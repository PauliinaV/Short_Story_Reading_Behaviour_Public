
@book{gelman_data_2007,
	address = {Cambridge},
	title = {Data {Analysis} {Using} {Regression} and {Multilevel}/{Hierarchical} {Models}},
	isbn = {978-0-511-79094-2},
	url = {https://doi.org/10.1017/CBO9780511790942},
	abstract = {Data Analysis Using Regression and Multilevel/Hierarchical Models, first published in 2007, is a comprehensive manual for the applied researcher who wants to perform data analysis using linear and nonlinear regression and multilevel models. The book introduces a wide variety of models, whilst at the same time instructing the reader in how to fit these models using available software packages. The book illustrates the concepts by working through scores of real data examples that have arisen from the authors' own applied research, with programming codes provided for each one. Topics covered include causal inference, including regression, poststratification, matching, regression discontinuity, and instrumental variables, as well as multilevel logistic regression and missing-data imputation. Practical tips regarding building, fitting, and understanding are provided throughout.},
	language = {en},
	urldate = {2023-03-07},
	publisher = {Cambridge University Press},
	author = {Gelman, Andrew and Hill, Jennifer},
	year = {2007},
	doi = {10.1017/CBO9780511790942},
	note = {ISBN: 9780511790942}
}
@article{brysbaert_how_2019,
	title = {How many words do we read per minute? {A} review and meta-analysis of reading rate},
	volume = {109},
	issn = {0749-596X},
	shorttitle = {How many words do we read per minute?},
	url = {https://www.sciencedirect.com/science/article/pii/S0749596X19300786},
	doi = {10.1016/j.jml.2019.104047},
	abstract = {Based on the analysis of 190 studies (18,573 participants), we estimate that the average silent reading rate for adults in English is 238 words per minute (wpm) for non-fiction and 260 wpm for fiction. The difference can be predicted by taking into account the length of the words, with longer words in non-fiction than in fiction. The estimates are lower than the numbers often cited in scientific and popular writings. The reasons for the overestimates are reviewed. The average oral reading rate (based on 77 studies and 5965 participants) is 183 wpm. Reading rates are lower for children, old adults, and readers with English as second language. The reading rates are in line with maximum listening speed and do not require the assumption of reading-specific language processing. Within each group/task there are reliable individual differences, which are not yet fully understood. For silent reading of English non-fiction most adults fall in the range of 175–300 wpm; for fiction the range is 200–320 wpm. Reading rates in other languages can be predicted reasonably well by taking into account the number of words these languages require to convey the same message as in English.},
	language = {en},
	urldate = {2021-07-08},
	journal = {Journal of Memory and Language},
	author = {Brysbaert, Marc},
	month = dec,
	year = {2019},
	keywords = {Reading speed, Reading rate, Language differences, Oral reading, reading speed, Silent reading, Words per minute},
	pages = {104047},
}
@article{Chung2002,
	title = {The effect of letter-stroke boldness on reading speed in central and peripheral vision},
	volume = {43},
	abstract = {PURPOSE. Crowding, the adverse spatial interaction due to prox- imity of adjacent letters, has been suggested as an explanation for slow reading in peripheral vision. The purpose of this study was to examine whether reading speed can be improved in normal peripheral vision by increasing the letter spacing. Also tested was whether letter spacing imposes a different limit on reading speed of small versus large print. METHODS. Six normal observers read aloud single, short sen- tences presented on a computer monitor, one word at a time, by rapid serial visual presentation (RSVP). Reading speeds were calculated based on the RSVP exposure durations yielding 80\% correctly read words. Letters were rendered in Courier, a fixed-width font. Testing was conducted at the fovea, 5° and 10° in the inferior visual field. The critical print size (CPS) was first determined for each observer by measuring reading speeds for four print sizes, using the standard letter spacing (center-to-center separation of adjacent letters; standard Cou- rier spacing: 1.16 times the width of the lowercase x). Text was then presented at 0.8x or 1.5x CPS, and reading speed was measured for five letter spacings, ranging from 0.5 times to 2 times the standard spacing. RESULTS. As expected, reading speed was highest at the fovea, decreased with eccentricity, and was faster for the larger print size. At all eccentricities and for both print sizes, reading speed increased with letter spacing, up to a critical letter spacing, and then either remained constant at the same reading speed or decreased slightly for larger letter spacings. The value of the critical letter spacing was very close to the standard letter spacing and did not depend on eccentricity or print size. CONCLUSIONS. Increased letter spacing beyond the standard size, which presumably decreases the adverse effect of crowding, does not lead to an increase in reading speed in central or peripheral vision. (Invest Ophthalmol Vis Sci. 2002;43: 1270–1276)},
	number = {4},
	journal = {Investigative Ophthalmology \& Visual Science},
	author = {Chung, Susana T.L.},
	year = {2002},
	keywords = {Reading, Peripheral vision, Stroke boldness},
	pages = {33-42}
}
@article{barrRandomEffectsStructure2013a,
  title = {Random Effects Structure for Confirmatory Hypothesis Testing: {{Keep}} It Maximal},
  shorttitle = {Random Effects Structure for Confirmatory Hypothesis Testing},
  author = {Barr, Dale J. and Levy, Roger and Scheepers, Christoph and Tily, Harry J.},
  year = {2013},
  month = apr,
  journal = {Journal of Memory and Language},
  volume = {68},
  number = {3},
  pages = {255--278},
  issn = {0749596X},
  doi = {10.1016/j.jml.2012.11.001},
  urldate = {2023-10-17},
  langid = {english}
}
@article{schielzethRobustnessLinearMixedeffects2020,
  title = {Robustness of Linear Mixed-Effects Models to Violations of Distributional Assumptions},
  author = {Schielzeth, Holger and Dingemanse, Niels J. and Nakagawa, Shinichi and Westneat, David F. and Allegue, Hassen and Teplitsky, C{\'e}line and R{\'e}ale, Denis and Dochtermann, Ned A. and Garamszegi, L{\'a}szl{\'o} Zsolt and {Araya-Ajoy}, Yimen G.},
  year = {2020},
  journal = {Methods in Ecology and Evolution},
  volume = {11},
  number = {9},
  pages = {1141--1152},
  issn = {2041-210X},
  doi = {10.1111/2041-210X.13434},
  urldate = {2023-01-31},
  abstract = {Linear mixed-effects models are powerful tools for analysing complex datasets with repeated or clustered observations, a common data structure in ecology and evolution. Mixed-effects models involve complex fitting procedures and make several assumptions, in particular about the distribution of residual and random effects. Violations of these assumptions are common in real datasets, yet it is not always clear how much these violations matter to accurate and unbiased estimation. Here we address the consequences of violations in distributional assumptions and the impact of missing random effect components on model estimates. In particular, we evaluate the effects of skewed, bimodal and heteroscedastic random effect and residual variances, of missing random effect terms and of correlated fixed effect predictors. We focus on bias and prediction error on estimates of fixed and random effects. Model estimates were usually robust to violations of assumptions, with the exception of slight upward biases in estimates of random effect variance if the generating distribution was bimodal but was modelled by Gaussian error distributions. Further, estimates for (random effect) components that violated distributional assumptions became less precise but remained unbiased. However, this particular problem did not affect other parameters of the model. The same pattern was found for strongly correlated fixed effects, which led to imprecise, but unbiased estimates, with uncertainty estimates reflecting imprecision. Unmodelled sources of random effect variance had predictable effects on variance component estimates. The pattern is best viewed as a cascade of hierarchical grouping factors. Variances trickle down the hierarchy such that missing higher-level random effect variances pool at lower levels and missing lower-level and crossed random effect variances manifest as residual variance. Overall, our results show remarkable robustness of mixed-effects models that should allow researchers to use mixed-effects models even if the distributional assumptions are objectively violated. However, this does not free researchers from careful evaluation of the model. Estimates that are based on data that show clear violations of key assumptions should be treated with caution because individual datasets might give highly imprecise estimates, even if they will be unbiased on average across datasets.},
  langid = {english},
  keywords = {biostatistics,correlated predictors,distributional assumptions,linear mixed-effects models,missing random effects,statistical quantification of individual differences (SQuID)}
}
