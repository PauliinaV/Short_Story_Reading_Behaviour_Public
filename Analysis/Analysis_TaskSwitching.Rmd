---
title: "Analysis_ReadingFrequency"
author: "Pauliina Vuorinen"
date: "08/10/2022-08/03/2023"
output: html_document
library: ["~/Extra/RPackages.bib", "~/Extra/InCodeCitations.bib"]
csl : ~/Extra/apa-7th-ed.csl
---

# Introduction

The purpose of this script is to model task-switching frequency. We aim to assess how participants' task-switching frequency varies during the study, and whether autonomy condition, contextual reading motivation, and electronic reading experience are connected to frequency of task-switching. See the full article for details.

To answer these questions, we use 'continuous engagement duration' (created in Prep_TaskSwitchingMeasure.Rmd in Prep folder) as a measure of task-switching frequency. The measure indicates how long the participants engaged with the text before disengaging from it. Therefore, short continuous engagement durations are taken as an indication of more frequent task-switching than longer continuous engagement durations.

Continuous engagement duration is modelled by **reader characteristics** to address our hypotheses. The model structure was theoretically motivated. See more information in the full article. The model is constructed using lmer() in the lme4-package by @bates_fitting_2015.

**Information on hypotheses:**

* H2a: Situational autonomous motivation is connected to lower task-switching frequency
* H2b: Contextual autonomous motivation is connected to lower task-switching frequency
* H2c: Task-relevant electronic reading experience (TR-EEXP) is connected to lower task-switching frequency

# Setup

```{r 'setup'}
library(tidyverse)
library(dplyr)
library(psych)
library(gridExtra)
library(corrplot)
library(lme4)
library(lmerTest)
library(performance)
library(car)
library(effects)
library(interactions)
library(jtools)
```
Save working directory so that this script can be used elsewhere, if required. The working directory should be "~/Short-Story-Reading-Behaviour-Public/". If the working directory is not correct, we save the correct path and use that in loading files.

The working directory is not changed with setwd() because this script is knit remotely in other scripts. If using remotely, define 'AnalysisFilePath'. AnalysisFilePath refers to this exact file location, and so path to the main folder "Short_Story_Reading_Behaviour_Public" is two folders lower.

```{r 'setwd'}
getwd() # working directory should be ~/Short_Story_Reading_Behaviour_Public
# If AnalysisFilePath is not defined, use setwd() to refer to the main folder
# setwd()
if (exists("AnalysisFilePath")) {
    mypath_SSRBP <- dirname(dirname(AnalysisFilePath))
} else {
    mypath_SSRBP <- getwd()
}
```

```{r 'load-figure-theme-for-consistency', echo=FALSE, warning="hide"}
source(
    paste0(
        mypath_SSRBP,
        "/Fig/Fig_FigureTheme.R"
    )
)
```

```{r 'load-helmert-contrasts-functions'}
source(
    paste0(
        mypath_SSRBP,
        "/Functions/Functions_contr.helmert.weighted.R"
    )
)
source(
    paste0(
        mypath_SSRBP,
        "/Functions/Functions_contr.helmert.unweighted.R"
    )
)
```

```{r 'source-functions-for-line-adding'}
source(
    paste0(
        mypath_SSRBP,
        "/Functions/Functions_AddLine.R"
    )
)
```

```{r 'source-function-for-variabletype-conversion'}
source(
    paste0(
        mypath_SSRBP,
        "/Functions/Functions_VariableTypeConversion.R"
    )
)
```

# Load data

Load the task-switching measure dataset:

```{r 'load-measure'}
task_switching_data <-
    read.csv(
        paste0(
            mypath_SSRBP,
            "/Data/task_switching_data.csv"
        ),
        header = TRUE,
        sep = ";",
        dec = ","
    )
task_switching_data <- dplyr::select(task_switching_data, -X) # remove row numbers
```

The sample includes *n* = `r length(unique(task_switching_data$UserId))` participants, indicating that all participants have at least one observation. The total amount of observations is `r nrow(task_switching_data)`.

We then load in questionnaire data:

```{r 'load-predictors:-questionnaires'}
# IMI
IMI_scores <-
    read.csv(
        paste0(
            mypath_SSRBP,
            "/Data/IMI_scores.csv"
        ),
        header = TRUE,
        sep = ";",
        dec = ","
    )
IMI_scores <- dplyr::select(IMI_scores, -X) # remove row numbers
# IMI-R
IMIR_scores <-
    read.csv(
        paste0(
            mypath_SSRBP,
            "/Data/IMIR_scores.csv"
        ),
        header = TRUE,
        sep = ";",
        dec = ","
    )
IMIR_scores <- dplyr::select(IMIR_scores, -X) # remove row numbers
# Electronic experience
eexp_scores <-
    read.csv(
        paste0(
            mypath_SSRBP,
            "/Data/eexp_scores.csv"
        ),
        header = TRUE,
        sep = ";",
        dec = ","
    )
eexp_scores <- dplyr::select(eexp_scores, -X) # remove row numbers
# demographic information
demographics_data <-
    read.csv(
        paste0(
            mypath_SSRBP,
            "/Data/demographics_data.csv"
        ),
        header = TRUE,
        sep = ";",
        dec = ","
    )
demographics_data <- dplyr::select(demographics_data, -X) # remove row numbers
```

Load in information about the stories that participants read:

```{r 'load-information-about-stories'}
story_information_data <-
    read.csv(
        paste0(
            mypath_SSRBP,
            "/Data/story_information_data.csv"
        ),
        header = TRUE,
        sep = ";",
        dec = ","
    )
story_information_data <- dplyr::select(story_information_data, -X) # remove row numbers
```

We then merge these dataframes together:

```{r 'merge-dfs'}
# measure and IMI
task_switching_data <- merge(
    task_switching_data,
    IMI_scores,
    all.x = TRUE,
    by = "UserId"
)
# measure and IMI-R
task_switching_data <- merge(
    task_switching_data,
    IMIR_scores,
    all.x = TRUE,
    by = "UserId"
)
# measure and EEXP
task_switching_data <- merge(
    task_switching_data,
    eexp_scores,
    all.x = TRUE,
    by = "UserId"
)
# measure and demographic information
task_switching_data <- merge(
    task_switching_data,
    demographics_data,
    all.x = TRUE,
    by = "UserId"
)
# measure and information about stories
task_switching_data <- merge(
    task_switching_data,
    story_information_data[, c(1:3, 8)],
    all.x = TRUE,
    by = "StoryId"
)
```

## Change variable types

```{r 'change-variable-types'}
str(task_switching_data)

## turn columns into factors that should be factors
task_switching_data[, c(
    "UserId",
    "StoryId"
)] <- convert.magic(
    task_switching_data[, c(
        "UserId",
        "StoryId"
    )],
    "factor"
)
```

## Reader characteristics model

The reader characteristics model aims to address the following hypotheses:

* H2a: Situational autonomous motivation is connected to lower task-switching frequency
* H2b: Contextual autonomous motivation is connected to lower task-switching frequency
* H2c: Task-relevant electronic reading experience (TR-EEXP) is connected to lower task-switching frequency

The reader characteristics model takes the following structure:

$Y_{i} = 
    \beta_{0} +
    WindowWidth +
    DUD +
    Native +
    Cond +
    SComp +
    CMot +
    CComp +
    TR-EExp1 +
    TR-EExp2 +
    TR-EExp1 x TR-EExp2 +
    u_{Story / Subject} +
    \varepsilon_{i}$ 

where
**$Y_{i}$** is the reading behaviour measure, in this case ContinuousEngagementMinutes for task-switching frequency. Shorter continuous engagement durations indicate of more frequent task-switching compared to long continuous continuous engagement durations.
**$\beta_{0}$** is the intercept
**WindowWidth** indicates screen size, measured by window width in pixels (which is affected by device and has an effect on how much text is visible)
**DUD** is an acronym for 'DaysUntilDeadline' which tells us how much the participant has time left to read the short story. Days until deadline is used to control for variance in reading behaviour as a result of pressure to read the short story in time. For example, participants may read the text differently closer to the deadline compared to the beginning of the study.
**Native** is a binary variable indicating whether the participant is a native speaker of English or not (responses - Yes/No, yes indicating that the participant is a native speaker).
**Cond** represents autonomy condition (as a measure of situational motivation)
**SComp** is participants' situational competence (perception of competence to read the story), measured by the subcomponent of 'competence' from the IMI questionnaire (see Prep_Questionnaires.Rmd in Prep folder)
**CMot** is participants' contextual reading motivation, measured by the subcomponent of contextual interest from the IMI-R questionnaire (see Prep_Questionnaires.Rmd in Prep folder)
**CComp** is participants' contextual competence (perception of general reading ability), measured by the subcomponent of 'competence' from the IMI-R questionnaire (see Prep_Questionnaires.Rmd in Prep folder)
**TR-EExp1** is frequency of using any electronic devices for long-form text reading purposes
**TR-EExp2** is frequency of using task-relevant devices for any reading purpose
**$u_{Story / Subject}$** indicates a nested random intercept of story and subject indicator. Each participant only read one short story during the study, and participant indicator is explicitly nested.
**$\varepsilon_{i}$** indicates the residual variance of $Y_{i}$

In addition to these predictors, models of linearity and speed of reading are also modelled with 'Cond x SComp', 'CMot x SComp', and 'TR-EExp1 x TR-EExp2 x SComp'. These additional interactions are needed to address all hypotheses, but they are not necessary in the model of task-switching frequency.

## Visualise task-switching

The task_switching_data has `r nrow(task_switching_data)` observations.

We create graphs to inspect task-switching and its connection to other variables.

The task-switching measure, ContinuousEngagementMinutes, is skewed towards lower values and the distribution may be improved by log-transformation.

```{r, include=FALSE}
# hist(task_switching_data$ContinuousEngagementMinutes, breaks = 50)
# hist(log(task_switching_data$ContinuousEngagementMinutes + 1), breaks = 50)
```

Variation between participants:

```{r, include=FALSE}
ggplot(task_switching_data, aes(x = UserId, y = ContinuousEngagementMinutes)) +
    geom_boxplot() +
    geom_jitter() +
    theme_classic() +
    ylab("Continuous Engagement Duration (Mins)")
```

Variation between different books read:

```{r, include=FALSE}
ggplot(
    task_switching_data,
    aes(x = StoryId, y = ContinuousEngagementMinutes)
) +
    geom_boxplot() +
    geom_jitter() +
    theme_classic() +
    ylab("Continuous Engagement Duration (Mins)")
```

We correct for story length to see if there are differences between different books read:

```{r, include=FALSE}
ggplot(task_switching_data, aes(x = StoryId, y = (ContinuousEngagementMinutes / CharacterLength))) +
    geom_boxplot() +
    geom_jitter() +
    theme_classic() +
    ylab("ContinuousEngagementMinutes/Book length")
```

We inspect individual variation within the different books read:

```{r, include=FALSE}
ggplot(
    task_switching_data,
    aes(x = StoryId, y = ContinuousEngagementMinutes)
) +
    geom_violin() +
    geom_jitter(aes(colour = UserId)) +
    theme_classic() +
    theme(
        legend.position = "none"
    ) +
    ylab("Continuous Engagement Duration (Mins)")
```

Create a formatted plot which shows variation between participants and books read. This plot is saved in Fig folder as Fig_TaskSwitchingVariance.png

```{r}
TaskSwitchingVariance <-
    ggplot(
        task_switching_data,
        aes(
            x = UserId,
            y = ContinuousEngagementMinutes,
            colour = StoryId
        )
    ) +
    geom_point(size = 2) +
    labs(
        y = addline_format("Continuous engagegement,duration (mins)"),
        x = "Participant indicator",
        colour = "Story indicator"
    ) +
    scale_fill_grey() +
    theme_bw() +
    theme(
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        axis.text.x = element_blank(),
        axis.text.y = element_text(size = 25),
        axis.ticks = element_blank(),
        axis.title.x = element_text(size = 25, vjust = 0.5),
        axis.title.y = element_text(size = 25, angle = 90, vjust = 0.5),
        plot.title = element_text(size = 20),
        legend.position = "none",
        strip.text.x = element_text(size = 16)
    )
```

The dataset includes three different measures of 'Days until deadline' (which reflects how close to the participant is to the end of the reading phase). These measures are the first and the last value of DaysUntilDeadline in a continuous engagement block, and the mean value of DaysUntilDeadline. The three measures are nearly perfectly correlated:

```{r}
cor(task_switching_data[, c(
    "LastDaysUntilDeadline",
    "FirstDaysUntilDeadline",
    "MeanDaysUntilDeadline"
)])
```

We select FirstDaysUntilDeadline as the measure of days until reading deadline. We reason that the pressure to read the book in time could plausible influence the decision to task-switch infrequently if the participant is close to the reading deadline at the beginning of the continuous engagement block. In contrast, 'LastDaysUntilDeadline' could be expected to have less of an impact on focus as the continuous engagement block has already passed. We do not use 'MeanDaysUntilDeadline' because the aggregation can distort the value.

We visualise the effect of FirstDaysUntilDeadline on ContinuousEngagementMinutes:

```{r, include=FALSE}
ggplot(task_switching_data, aes(x = FirstDaysUntilDeadline, y = ContinuousEngagementMinutes)) +
    geom_point(aes(colour = UserId), size = 3) +
    theme_classic() +
    theme(
        legend.position = "none"
    ) +
    ylab("Days Until Reading Deadline")
```

Similarly to DaysUntilDeadline, the dataset includes three different values for WindowWidth to account for the possibility that participants' browser window size changes during a continuous engagement block. Note that while it is possible that the reader resizes a window during a continuous engagement block (which would result in a change in the value of WindowWidth), it isn't possible that the reader changes their reading device within a continuous engagement block. Unsurprisingly, window width measurements are also very highly correlated:

```{r}
cor(task_switching_data[, c(
    "LastWindowWidth",
    "FirstWindowWidth",
    "MeanWindowWidth"
)])
```

Similarly to Days until deadline, we decide to use FirstWindowWidth rather than the last observation or the average value.

We visualise the effect of FirstWindowWidth on ContinuousEngagementMinutes:

```{r, include=FALSE}
ggplot(task_switching_data, aes(x = FirstWindowWidth, y = ContinuousEngagementMinutes)) +
    geom_point(aes(colour = UserId), size = 3) +
    theme_classic() +
    theme(
        legend.position = "none"
    ) +
    ylab("Days Until Reading Deadline") +
    geom_vline(xintercept = 1192)
```

### Task-switching and demographic information

Gender:

```{r, include=FALSE}
ggplot(task_switching_data, aes(x = Gender, y = ContinuousEngagementMinutes)) +
    geom_violin() +
    geom_jitter(aes(colour = UserId)) +
    theme_classic() +
    theme(
        legend.position = "none"
    ) +
    ylab("Continuous Engagement Duration (Mins)")
```

Age:

```{r, include=FALSE}
ggplot(task_switching_data, aes(x = Age, y = ContinuousEngagementMinutes)) +
    geom_point() +
    theme_classic() +
    theme(
        legend.position = "none"
    ) +
    ylab("Continuous Engagement Duration (Mins)")
```

Whether participants' native language is English or not:

```{r, include=FALSE}
ggplot(task_switching_data, aes(x = NativeEnglish, y = ContinuousEngagementMinutes)) +
    geom_violin() +
    geom_jitter(aes(colour = UserId)) +
    theme_classic() +
    theme(
        legend.position = "none"
    ) +
    ylab("Continuous Engagement Duration (Mins)")
```

### Condition

```{r, include=FALSE}
ggplot(task_switching_data, aes(x = Condition, y = ContinuousEngagementMinutes)) +
    geom_boxplot() +
    theme_classic() +
    ylab("Continuous Engagement Duration (Mins)")
```

### Motivation

Only situational competence is included in the model from the IMI variables, considering that condition is significantly connected to both situational autonomy and interest.

Situational competence:

```{r, include=FALSE}
ggplot(task_switching_data, aes(x = SCompetence, y = ContinuousEngagementMinutes)) +
    geom_smooth() +
    geom_point() +
    theme_classic() +
    theme(
        legend.position = "none"
    ) +
    ylab("Continuous Engagement Duration (Mins)")
```

We then create visualisations for contextual measures of motivation: interest and competence.

Contextual interest:

```{r, include=FALSE}
ggplot(task_switching_data, aes(x = CInterest, y = ContinuousEngagementMinutes)) +
    geom_smooth() +
    geom_point() +
    theme_classic() +
    theme(
        legend.position = "none"
    ) +
    ylab("Continuous Engagement Duration (Mins)")
```

Contextual competence:

```{r, include=FALSE}
ggplot(task_switching_data, aes(x = CCompetence, y = ContinuousEngagementMinutes)) +
    geom_smooth() +
    geom_point() +
    theme_classic() +
    theme(
        legend.position = "none"
    ) +
    ylab("Continuous Engagement Duration (Mins)")
```

### Task switching and electronic reading experience

We are interested in how task-relevant electronic experience is connected to task-switching.
Electronic experience was measured by two variables: Eexp1LongFormEFreq - the frequency of reading long-form, narrative texts electronnically, and Eexp2DeviceRecFreq - the frequency of using task-relevant digital devices for recreational reading purposes.

Eexp1LongformEFreq (longfrom reading electronically):

```{r, include=FALSE}
ggplot(task_switching_data, aes(x = Eexp1LongformEFreq, y = ContinuousEngagementMinutes)) +
    geom_point() +
    theme_classic() +
    theme(
        legend.position = "none"
    ) +
    ylab("Continuous Engagement Duration (Mins)")
```

Eexp2DeviceRecFreq (task-relevant digital devices for recreational reading):

```{r, include=FALSE}
ggplot(task_switching_data, aes(x = Eexp2DeviceRecFreq, y = ContinuousEngagementMinutes)) +
    geom_smooth() +
    geom_point() +
    theme_classic() +
    theme(
        legend.position = "none"
    ) +
    ylab("Continuous Engagement Duration (Mins)")
```

## Create contrasts to predictors

Predictors in the model are given contrasts. Continuous variables are scaled and centered, whereas categorical variables are given helmert contrasts. Helmert contrasts are used to control for uneven levels in categorical variables.

Contrasts for categorical variables:

```{r 'categorical-contrasts'}
# whether native language is English or not
task_switching_data$NativeEnglish <- as.factor(task_switching_data$NativeEnglish)
contrasts(task_switching_data$NativeEnglish) <- contr.helmert.unweighted(task_switching_data$NativeEnglish)
contrasts(task_switching_data$NativeEnglish)
# condition
task_switching_data$Condition <- dplyr::recode(
    task_switching_data$Condition,
    "AutonomousCondition" = "HighAutonomyCondition",
    "NonAutonomousCondition" = "LowAutonomyCondition"
)
task_switching_data$Condition <- as.factor(task_switching_data$Condition)
contrasts(task_switching_data$Condition) <- contr.helmert.unweighted(
    task_switching_data$Condition
)
contrasts(task_switching_data$Condition)
```

Next, we scale and center continuous variables. These variables names are appended with ".cs" as a reminder that the variable is scaled and centered.

```{r 'scale-continuous-variables'}
# Situational competence
task_switching_data$SCompetence.sc <-
    scale(task_switching_data$SCompetence,
        center = TRUE,
        scale = TRUE
    )
# Contextual motivation
task_switching_data$CInterest.sc <-
    scale(task_switching_data$CInterest,
        center = TRUE,
        scale = TRUE
    )
task_switching_data$CCompetence.sc <-
    scale(task_switching_data$CCompetence,
        center = TRUE,
        scale = TRUE
    )
# Electronic reading experience
task_switching_data$Eexp1LongformEFreq.sc <-
    scale(task_switching_data$Eexp1LongformEFreq,
        center = TRUE,
        scale = TRUE
    )
task_switching_data$Eexp2DeviceRecFreq.sc <-
    scale(task_switching_data$Eexp2DeviceRecFreq,
        center = TRUE,
        scale = TRUE
    )
# Days until reading deadline
task_switching_data$DaysUntilDeadline.sc <-
    scale(task_switching_data$FirstDaysUntilDeadline,
        center = TRUE,
        scale = TRUE
    )
# Window width
task_switching_data$WindowWidth.sc <-
    scale(task_switching_data$FirstWindowWidth,
        center = TRUE,
        scale = TRUE
    )
```

## Model of Task Switching

First, we build the full structure. Refer to the beginning of this script to see information on the full structure. The full model includes 13 parameters, and `r nrow(task_switching_data)` observations. Previous research has suggested that each parameter in a model has 15 observations. Our sample is close to this threshold considering that `r nrow(task_switching_data)`/13 = `r round(nrow(task_switching_data)/13, 2)`

```{r 'define-full-structure'}
FullStructure_nested <- (
    "log(ContinuousEngagementMinutes + 1) ~ WindowWidth.sc + DaysUntilDeadline.sc + NativeEnglish + Condition + SCompetence.sc + CInterest.sc + CCompetence.sc + Eexp1LongformEFreq.sc + Eexp2DeviceRecFreq.sc +  Eexp1LongformEFreq.sc : Eexp2DeviceRecFreq.sc + (1 | StoryId / UserId)"
)
```

```{r 'fit-model'}
TaskSwitching_FullModel_nested <- lmer(
    FullStructure_nested,
    data = task_switching_data,
    control = lmerControl(optimizer = "bobyqa"),
    REML = TRUE
)
```

The full model reaches convergence.
Inspect model values:

```{r}
summary(TaskSwitching_FullModel_nested)
plot(TaskSwitching_FullModel_nested)
fixef(TaskSwitching_FullModel_nested)
```

### Model Assumptions

All models were tested for (1) multicollinearity, (2) heteroscedasticity, (3) influential observations, and (4) normality of random effects

#### 1. Multicollinearity

We check for multicollinearity first with a correlation matrix:

```{r}
# corrplot(cor(task_switching_data[, c(
#     "WindowWidth.sc",
#     "DaysUntilDeadline.sc",
#     "SCompetence.sc",
#     "CInterest.sc",
#     "CCompetence.sc",
#     "Eexp1LongformEFreq.sc",
#     "Eexp2DeviceRecFreq.sc"
#     )]), method = "number")
```

Some of the variables show high correlations. For example, contextual reading competence is correlated with situational competence (*r* = `r round(cor(task_switching_data$SCompetence, task_switching_data$CCompetence), 2)`) and contextual motivation (*r* = `r round(cor(task_switching_data$CCompetence, task_switching_data$CInterest), 2)`).

To check if these correlations are problematic, we calculate Variance Inflation Factors (VIF):

```{r, include=FALSE}
check_collinearity(TaskSwitching_FullModel_nested)
# plot(check_collinearity(TaskSwitching_FullModel_nested))
```

Despite of the correlations, the model predictors do not seem to be multicollinear. All VIF < 2.5, and usually VIF > 5 is used as an indicator of potential multicollinearity.

#### 2. Heteroscedasticity

We use the Breusch-Pagan test to check whether the variances of residuals in the model vary systematically:

```{r, include=FALSE}
check_heteroscedasticity(TaskSwitching_FullModel_nested)
# plot(check_heteroscedasticity(TaskSwitching_FullModel_nested))
```

The p-value is not significant, which indicates that the residuals are homoscedastic. Also, the plot line seems to be fairly flat and horizontal, indicating of homoscedasticity.

We check categorical predictors separately with a Levene's test:

```{r}
leveneTest(residuals(TaskSwitching_FullModel_nested) ~ task_switching_data$Condition)
```

```{r}
leveneTest(residuals(TaskSwitching_FullModel_nested) ~ task_switching_data$NativeEnglish)
```

The assumption of equal variables is met for both Condition and NativeEnglish.

#### 3. Influential Observations

We test influential observations with Cook's Distance:

```{r, include=FALSE}
# cooksd <-
#      cooks.distance(TaskSwitching_FullModel_nested)
# plot(cooksd,
#    pch = "*",
#     cex = 2,
#     main = "Influential Obs by Cooks Distance"
# )
# abline(h = 4 * mean(cooksd, na.rm = TRUE), col = "red")
# text(
#     x = 1:length(cooksd) + 1,
#     y = cooksd,
#     labels = ifelse(cooksd > 4 * mean(cooksd, na.rm = TRUE), names(cooksd), ""),
#     col = "red"
# )
```

The plot indicates that some observations may be influential. However, the Cook's Distance threshold is very conservative at `r round((4 * mean(cooksd, na.rm = TRUE)), 2)`.

We further inspect Cook's Distance with a different plot:

```{r, include=FALSE}
check_outliers(TaskSwitching_FullModel_nested)
plot(check_outliers(TaskSwitching_FullModel_nested))
```

Usage of a less conservative limit (Cook's Distance > .5 for influential observations) indicates that none of the observations are influential. We trust this judgement after off-script experimentation indicated that removal of the most influential observation flagged earlier does not affect results.

#### 4. Normality of Random Effects

Random effects should be normally distributed in multilevel models. We test this assumption by inspecting first the normality of 'UserId' and then 'StoryId' random intercepts.

```{r, include=FALSE}
random_intercept_UserId <- ranef(TaskSwitching_FullModel_nested)$UserId$`(Intercept)`
# qqnorm(random_intercept_UserId)
# qqline(random_intercept_UserId)
shapiro.test(random_intercept_UserId)
```

The qqplot slightly varies from the reference line, but considering that the variance is not extensive and the Shapiro Test is not significant, we assume that UserId random intercept is normally distributed

```{r, include=FALSE}
random_intercept_StoryId <- ranef(TaskSwitching_FullModel_nested)$StoryId$`(Intercept)`
# qqnorm(random_intercept_StoryId)
# qqline(random_intercept_StoryId)
shapiro.test(random_intercept_StoryId)
```

StoryId aligns much worse with the reference line, however, this is expected considering that StoryId only includes 9 different story groups. With the limited amount of information, achieving a visually normally distributed result is unlikely. Considering that the Shapiro Test is not significant, we can assume that StoryId random intercept is normally distributed.

**Assumptions conclusion**

The model aligns with all assumptions.

### Interpret model

We then interpret model effects to study the results.

```{r}
summary(TaskSwitching_FullModel_nested)
```

Only situational competence, contextual motivation (CInterest) and contextual competence are significant predictors in the model.

#### Hypotheses

**H2a: Situational autonomous motivation is connected to lower task-switching frequency.**

This hypothesis was not supported as Condition was not a significant predictor of task-switching frequency in the model.

```{r, warning='hide'}
taskswitching_effectplot_condition <- effect_plot(
    TaskSwitching_FullModel_nested,
    pred = "Condition",
    data =  task_switching_data,
    plot.points = TRUE,
    point.size = 2,
    interval = TRUE,
    point.shape = TRUE
) +
    theme_bw() +
    figure_theme_without_legend +
    labs(
        y = addline_format("Continuous engagement duration,(min)"),
        x = addline_format("Condition")
    ) +
    coord_cartesian(ylim = c(0.6931472, 4.5)) +
    scale_y_continuous(breaks = c(
        0.6931472,
        2.484907,
        3.465736,
        3.951244,
        4.276666
    ), labels = c(
        "0",
        "10",
        "30",
        "50",
        "70"
    ))
```

Participants in the high-autonomy and low-autonomy conditions did not differ significantly in their continuous engagement durations

**H2b: Contextual autonomous motivation is connected to lower task-switching frequency**

Contextual motivation (measured by CInterest) was a significant predictor of continuous engagement duration.

```{r, warning='hide'}
taskswitching_effectplot_contextualmotivation <- effect_plot(
    TaskSwitching_FullModel_nested,
    pred = "CInterest.sc",
    data =  task_switching_data,
    plot.points = TRUE,
    point.size = 1,
    interval = TRUE,
    point.shape = TRUE
) +
    figure_theme_without_legend +
    labs(
        y = addline_format("Continuous engagement duration,(min)"),
        x = addline_format("Contextual motivation score, measured by contextual reading interest,(centered and scaled)")
    ) +
    coord_cartesian(ylim = c(0.6931472, 4.5)) +
    scale_y_continuous(breaks = c(
        0.6931472,
        2.484907,
        3.465736,
        3.951244,
        4.276666
    ), labels = c(
        "0",
        "10",
        "30",
        "50",
        "70"
    ))
```

Participants with more autonomous contextual motivation engaged for longer continuously and thus task-switched less frequently than participants with lower levels of contextual motivation. Therefore, our hypothesis H2b was supported.

**H2c: Task-relevant electronic reading experience (TR-EEXP) is connected to lower task-switching frequency**

This hypothesis was not supported as neither of the electronic experience measures was a significant predictor of task-switching frequency in the model.

```{r}
taskswitching_effectplot_electronicexperience <-
    interact_plot(TaskSwitching_FullModel_nested,
        pred = Eexp1LongformEFreq.sc,
        modx = Eexp2DeviceRecFreq.sc,
        data = task_switching_data,
        plot.points = TRUE,
        point.alpha = .2,
        point.size = 1,
        jitter = .5,
        interval = TRUE,
        legend.main = addline_format("Electronic experience 2"),
        colors = c("orange", "darkred", "navy"),
        point.shape = TRUE
    ) +
    figure_theme_with_top_legend +
    labs(
        y = "Continuous engagement duration (min)",
        x = addline_format("Electronic experience 1:,Frequency of reading longform texts electronically,(centered and scaled)"),
        caption = addline_format("Legend variable: Frequency of using task-relevant digital devices,for recreational reading (centered and scaled)")
    ) +
    coord_cartesian(ylim = c(0.6931472, 4.5)) +
    scale_y_continuous(breaks = c(
        0.6931472,
        2.484907,
        3.465736,
        3.951244,
        4.276666
    ), labels = c(
        "0",
        "10",
        "30",
        "50",
        "70"
    ))
```

However, the trend of the results is what we would expect - a combination of both types of electronic experience is associated with a slightly higher continuous engagement duration. However, the interaction is not significant, and therefore, hypothesis H2c was not supported.

#### Other results

In addition to contextual motivation, Continuous engagement duration was significantly predicted by situational competence (SCompetence.sc) and contextual competence (CCompetence.sc). Next, we inspect these significant effects.

**Situational competence**

```{r, warning='hide'}
taskswitching_effectplot_situationalcompetence <- effect_plot(
    TaskSwitching_FullModel_nested,
    pred = "SCompetence.sc",
    data =  task_switching_data,
    plot.points = TRUE,
    point.size = 2,
    interval = TRUE,
    point.shape = TRUE
) +
    figure_theme_without_legend +
    labs(
        y = addline_format("Continuous engagement duration,(min)"),
        x = addline_format("Situational perceived competence,score (centered and scaled)")
    ) +
    coord_cartesian(ylim = c(0.6931472, 4.5)) +
    scale_y_continuous(breaks = c(
        0.6931472,
        2.484907,
        3.465736,
        3.951244,
        4.276666
    ), labels = c(
        "0",
        "10",
        "30",
        "50",
        "70"
    ))
```

Situational competence is positively connected to continuous engagement duration, indicating that participants who found the text easier to read, task-switched infrequently.

**Contextual Competence**

```{r, warning='hide'}
taskswitching_effectplot_contextualcompetence <- effect_plot(
    TaskSwitching_FullModel_nested,
    pred = "CCompetence.sc",
    data =  task_switching_data,
    plot.points = TRUE,
    point.size = 2,
    interval = TRUE,
    point.shape = TRUE
) +
    figure_theme_without_legend +
    labs(
        y = "Continuous engagement duration (min)",
        x = addline_format("Contextual perceived competence, score (centered and scaled)")
    ) +
    coord_cartesian(ylim = c(0.6931472, 4.5)) +
    scale_y_continuous(breaks = c(
        0.6931472,
        2.484907,
        3.465736,
        3.951244,
        4.276666
    ), labels = c(
        "0",
        "10",
        "30",
        "50",
        "70"
    ))
```

Whereas situational competence score is positively connected to continuous engagement duration, interestingly, contextual competence is negatively connected to it. Therefore, participants who found judged themselves to have a generally high reading ability were more likely to task-switch frequently than participants who reported lower general reading skills.

