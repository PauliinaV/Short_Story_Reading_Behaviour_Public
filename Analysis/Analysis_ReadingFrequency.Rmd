---
title: "Analysis_ReadingFrequency"
author: "Pauliina Vuorinen"
date: "03/10/2022-"
output: html_document
library: "~/Extra/RPackages.bib"
---

## Introduction

The purpose of this script is to model reading frequency. The measure for reading frequency was created in Prep_ReadingFrequencyMeasure.rmd (in Prep folder).

### Reading frequency measure

Reading frequency indicates how often an individual engages in reading.

We measure reading frequency by the time in between reading sessions. This duration indicates how often participants decide to continue reading their selected book, and so shorter times in between reading sessions are assummed to tell us of a higher reading frequency than longer times in between reading sessions. This measure was chosen instead of, for example, the amount of reading sessions, to capture individual variance.

Considering that the reading frequency measure is time in between reading sessions, the frequency could not be measured for participants that only have one reading session. These participants' reading frequency is set to '0' as an that there was no time in between reading sessions (high reading frequency).

**Hypotheses**

(1) Situational autonomous motivation (as in high-autonomy condition) is connected to higher reading frequency.

(2) Contextual autonomous motivation is connected to higher reading frequency.

(3) Higher levels of task-relevant electronic reading experience is connected to higher reading frequency.

### Modelling approach

Reading behaviour measures were modelled by multilvel level models. Depending on the outcome variable distribution, we used either linear mixed models or generalised linear mixed models with R and the lme4 package (Bates et al., 2015), and p-values were estimated with the lmerTest package (Kuznetsova et al., 2017). All reading behaviour measures were create a model on *reader characteristics* which included predictors such as situational motivation, contextual motivation, and electronic experience (see below for the full structure). Furthermore, reading behaviour measures that were measured on a page-level (reading speed variance and linearity) were also modelled by *event characteristics* which included predictors such as location in the text, and previous event (full structure in reading speed and linearity models, see Analysis folder). Each model was simplified by manual backward stepwise method by removing predictors that least contributed to the model one by one, until the model reached convergence, or was no longer considered to be singular. All models were tested for multicollinearity, non-normality of residuals, homoscedasticity, influential observations, and normality of random effects (included in this script).

#### Reading frequency: reader characteristics model, full structure

The full model structure was as follows, see below for brief explanations on individual variables. See the information folder for more detail on why this particular structure was chosen.


```
TimeBetweenReadingSessions ~

    # control variable:
    DaysUntilReadingDeadline +

    # demographic information:
    IsNativeEnglishSpeaker +

    # Situational motivation:
    Condition +
    SCompetence +

    # Contextual motivation
    CInterest +
    CCompetence +

    # Electronic reading experience
    Device +
    TextTypes +

    # Interactions
    # Condition * SCompetence + # speed + linearity
    # CInterest * SCompetence + # speed + linearity
    Device * TextTypes +
    # Device * TextTypes * SCompetence # speed + linearity

    # Random effects
    (1 | UserId)
    (1 | StoryId)
```

Outcome variable:

- TimeBetweenReadingSessions: measure of reading frequency
    - 

Fixed effects:

- DaysUntilReadingDeadline: indicator of how close to the end of the study participant is at the moment of their last reading event
    - This variable is mainly included to account for random variation, for example, from pressure to read to finish the text close to the deadline

- Condition: Manipulation of autonomy in story selection
    - High-autonomy and low-autonomy condition
    - Used as a measure of situational interest and autonomy after manipulation analysis indicated that participants significantly differed in their autonomy and interest based on condition

- S_Competence: Situational reading competence
    - 
- S_Choice: Situational reading autonomy

Random effects:

- UserId: participant indicator
  - To account for the random variation from different participants (individual variance)
- BookId: text indicator
    - To account for the random variation from different books being read

For reading behaviour measures calculated on the page-level we also include a random intercept of WindowWidth to reflect device size.

## Setup

```{r}
library(tidyverse)
library(dplyr)
library(psych)
library(wesanderson)
library(gridExtra)
library(corrplot)
library(lme4)
library(lmerTest)
library(performance)
library(car)
```

Save working directory so that this script can be used elsewhere, if required. The working directory should be "~/Short-Story-Reading-Behaviour-Public/". If the working directory is not correct, we save the correct path and use that in loading files. In our purposes, the foulder could be found from /Documents/GITHUB/Short_Story_Reading_Behaviour_Public.

The working directory is not changed with setwd() because this script is knit remotely in other scripts.

```{r 'working directory for my purposes'}
mypath_SSRBP <- getwd()
if (!grepl("Short_Story_Reading_Behaviour_Public", mypath_SSRBP, fixed = TRUE)) {
    # wrong working directory
    if (!grepl("GITHUB", dirname(mypath_SSRBP), fixed = TRUE)) {
        # directory name isn't GITHUB, unlike I would expect
        if (grepl("GITHUB", mypath_SSRBP, fixed = TRUE)) {
            # GITHUB is in the path
            ## use mypath_SSRBP instead of dirname()
            mypath_SSRBP <- paste0(
                mypath_SSRBP,
                "/Short_Story_Reading_Behaviour_Public"
            )
        }
    } else {
        # directory name is GITHUB
        # save correct working directory
        mypath_SSRBP <- paste0(
            dirname(mypath_SSRBP),
            "/Short_Story_Reading_Behaviour_Public"
        )
    }
}
```

## Load data

Load first the reading frequency measure dataset:

```{r 'load measure'}
reading_frequency_data <-
    read.csv(
        paste0(
            mypath_SSRBP,
            "/Data/reading_frequency_data.csv"
        ),
        header = TRUE,
        sep = ";",
        dec = ","
    )
reading_frequency_data <- dplyr::select(reading_frequency_data, -X) # remove row numbers
```

Participants with multiple reading sessions have their first reading session's TimeBetweenReadingSessions marked as NA. These events are removed:

```{r}
reading_frequency_data <- filter(reading_frequency_data, !(is.na(TimeBetweenReadingSessions)))
```

The removal of NA has no impact on sample size: *n* = `r length(unique(reading_frequency_data$UserId))`

We then load in questionnaire data:

```{r 'load predictors: questionnaires'}
# IMI
IMI_scores <-
    read.csv(
        paste0(
            mypath_SSRBP,
            "/Data/IMI_scores.csv"
        ),
        header = TRUE,
        sep = ";",
        dec = ","
    )
IMI_scores <- dplyr::select(IMI_scores, -X) # remove row numbers
# IMI-R
IMIR_scores <-
    read.csv(
        paste0(
            mypath_SSRBP,
            "/Data/IMIR_scores.csv"
        ),
        header = TRUE,
        sep = ";",
        dec = ","
    )
IMIR_scores <- dplyr::select(IMIR_scores, -X) # remove row numbers
# Electronic experience
eexp_scores <-
    read.csv(
        paste0(
            mypath_SSRBP,
            "/Data/eexp_scores.csv"
        ),
        header = TRUE,
        sep = ";",
        dec = ","
    )
eexp_scores <- dplyr::select(eexp_scores, -X) # remove row numbers
# demographic information
demographics_data <-
    read.csv(
        paste0(
            mypath_SSRBP,
            "/Data/demographics_data.csv"
        ),
        header = TRUE,
        sep = ";",
        dec = ","
    )
demographics_data <- dplyr::select(demographics_data, -X) # remove row numbers
```

Load in information about the stories that participants read:

```{r}
story_information_data <-
    read.csv(
        paste0(
            mypath_SSRBP,
            "/Data/story_information_data.csv"
        ),
        header = TRUE,
        sep = ";",
        dec = ","
    )
story_information_data <- dplyr::select(story_information_data, -X) # remove row numbers
```

We then merge these dataframes together:

```{r 'merge dfs'}
# measure and IMI
reading_frequency_data <- merge(
    reading_frequency_data,
    IMI_scores,
    all.x = TRUE,
    by = "UserId"
)
# measure and IMI-R
reading_frequency_data <- merge(
    reading_frequency_data,
    IMIR_scores,
    all.x = TRUE,
    by = "UserId"
)
# measure and EEXP
reading_frequency_data <- merge(
    reading_frequency_data,
    eexp_scores,
    all.x = TRUE,
    by = "UserId"
)
# measure and demographic information
reading_frequency_data <- merge(
    reading_frequency_data,
    demographics_data,
    all.x = TRUE,
    by = "UserId"
)
# measure and information about stories
reading_frequency_data <- merge(
    reading_frequency_data,
    story_information_data[, c(1:3, 10)],
    all.x = TRUE,
    by = "StoryId"
)
```

## Change variable types

```{r 'change variable types'}
str(reading_frequency_data)
source(
    paste0(
        mypath_SSRBP,
        "/Functions/Functions_VariableTypeConversion.R"
    )
)

## turn columns into factors that should be factors
reading_frequency_data[, c(
    "UserId",
    "StoryId"
)] <- convert.magic(
    reading_frequency_data[, c(
        "UserId",
        "StoryId"
    )],
    "factor"
)
```

## Visualise reading frequency

The reading_frequency_data has `r nrow(reading_frequency_data)` observations.

We create graphs to inspect reading frequency and its connection to other variables.

The reading frequency measure, TimeBetweenReadingSessions, is skewed towards lower values and the distribution may be improved by log-transformation.

```{r}
hist(reading_frequency_data$TimeBetweenReadingSessions, breaks = 50)
hist(log(reading_frequency_data$TimeBetweenReadingSessions + 1), breaks = 50)
```

However, the histograms indicate that the distribution is still strongly skewed towards lower values. The impact of the skewed distribution on the model is assessed later.

Variation between participants:

```{r}
ggplot(reading_frequency_data, aes(x = UserId, y = TimeBetweenReadingSessions / 60 / 24)) +
    geom_point() +
    theme_classic() +
    ylab("TimeBetweenReadingSessions (days)")
```

Variation between different books read:

```{r}
ggplot(
    reading_frequency_data,
    aes(x = StoryId, y = TimeBetweenReadingSessions / 60 / 24)
) +
    geom_boxplot() +
    geom_jitter() +
    theme_classic() +
    ylab("TimeBetweenReadingSessions (days)")
```

We correct for story length to see if there are differences between different books read:

```{r}
ggplot(reading_frequency_data, aes(x = StoryId, y = (TimeBetweenReadingSessions / CharacterLength))) +
    geom_boxplot() +
    geom_jitter() +
    theme_classic() +
    ylab("TimeBetweenReadingSessions/Book length") +
    ggtitle("Full dataset")
```

We inspect individual variation within the different books read:

```{r}
ggplot(
    reading_frequency_data,
    aes(x = StoryId, y = TimeBetweenReadingSessions / 60 / 24)
) +
    geom_violin() +
    geom_jitter(aes(colour = UserId)) +
    theme_classic() +
    theme(
        legend.position = "none"
    ) +
    ylab("TimeBetweenReadingSessions (days)")
```

Create a formatted plot which shows variation between participants and books read. This plot is saved in Fig folder as Fig_ReadingFrequencyVariance.png

```{r}
source(
    paste0(
        mypath_SSRBP,
        "/Functions/Functions_AddLine.R"
    )
)
FrequencyVariance <-
    ggplot(
        reading_frequency_data,
        aes(
            x = UserId,
            y = TimeBetweenReadingSessions / 60 / 24,
            colour = StoryId
        )
    ) +
    geom_point(size = 4) +
    labs(
        y = addline_format("Time between,reading session (days)"),
        x = "Participant indicator",
        colour = "Story indicator"
    ) +
    scale_fill_grey() +
    theme_bw() +
    theme(
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        axis.text.x = element_blank(),
        axis.text.y = element_text(size = 25),
        axis.ticks = element_blank(),
        axis.title.x = element_text(size = 25, vjust = 0.5),
        axis.title.y = element_text(size = 25, angle = 90, vjust = 0.5),
        plot.title = element_text(size = 20),
        legend.position = "none",
        strip.text.x = element_text(size = 16)
    ) +
    scale_y_continuous(labels = function(UserId) format(UserId, width = 2))
FrequencyVariance
```

Effect of DaysUntilDeadline:

```{r}
ggplot(reading_frequency_data, aes(x = DaysUntilDeadline, y = TimeBetweenReadingSessions / 60 / 24)) +
    geom_point(aes(colour = UserId), size = 3) +
    theme_classic() +
    theme(
        legend.position = "none"
    ) +
    ylab("Days Until Reading Deadline")
```


### Reading frequency and demographic information

Gender:

```{r}
ggplot(reading_frequency_data, aes(x = Gender, y = TimeBetweenReadingSessions / 60 / 24)) +
    geom_violin() +
    geom_jitter(aes(colour = UserId)) +
    theme_classic() +
    theme(
        legend.position = "none"
    ) +
    ylab("TimeBetweenReadingSessions (days)")
```

Age:

```{r}
ggplot(reading_frequency_data, aes(x = Age, y = TimeBetweenReadingSessions / 60 / 24)) +
    geom_point() +
    theme_classic() +
    theme(
        legend.position = "none"
    ) +
    ylab("TimeBetweenReadingSessions (days)")
```

Whether participants' native language is English or not:

```{r}
ggplot(reading_frequency_data, aes(x = NativeEnglish, y = TimeBetweenReadingSessions / 60 / 24)) +
    geom_violin() +
    geom_jitter(aes(colour = UserId)) +
    theme_classic() +
    theme(
        legend.position = "none"
    ) +
    ylab("TimeBetweenReadingSessions (days)")
```

### Reading frequency and condition

```{r}
ggplot(reading_frequency_data, aes(x = Condition, y = TimeBetweenReadingSessions / 60 / 24)) +
    geom_boxplot() +
    theme_classic() +
    ylab("TimeBetweenReadingSessions (days)")
```

### Motivation

Only situational competence is included in the model from the IMI variables, considering that condition is significantly connected to both situational autonomy and interest.

Situational competence:

```{r}
ggplot(reading_frequency_data, aes(x = SCompetence, y = TimeBetweenReadingSessions / 60 / 24)) +
    geom_smooth() +
    geom_point() +
    theme_classic() +
    theme(
        legend.position = "none"
    ) +
    ylab("TimeBetweenReadingSessions (days)")
```

We then create visualisations for contextual measures of motivation: interest, competence, and effort.

Contextual interest:

```{r}
ggplot(reading_frequency_data, aes(x = CInterest, y = TimeBetweenReadingSessions / 60 / 24)) +
    geom_smooth() +
    geom_point() +
    theme_classic() +
    theme(
        legend.position = "none"
    ) +
    ylab("TimeBetweenReadingSessions (days)")
```

Contextual competence:

```{r}
ggplot(reading_frequency_data, aes(x = CCompetence, y = TimeBetweenReadingSessions / 60 / 24)) +
    geom_smooth() +
    geom_point() +
    theme_classic() +
    theme(
        legend.position = "none"
    ) +
    ylab("TimeBetweenReadingSessions (days)")
```

### Reading frequency and electronic reading experience

We are interested in how task-relevant electronic experience is connected to reading frequency.
Electronic experience was measured by two variables: Eexp1LongFormEFreq - the frequency of reading long-form, narrative texts electronnically, and Eexp2DeviceRecFreq - the frequency of using task-relevant digital devices for recreational reading purposes.

Eexp1LongformEFreq (longfrom reading electronically):

```{r}
ggplot(reading_frequency_data, aes(x = Eexp1LongformEFreq, y = TimeBetweenReadingSessions / 60 / 24)) +
    geom_point() +
    theme_classic() +
    theme(
        legend.position = "none"
    ) +
    ylab("TimeBetweenReadingSessions (days)")
```

Eexp2DeviceRecFreq (task-relevant digital devices for recreational reading):

```{r}
ggplot(reading_frequency_data, aes(x = Eexp2DeviceRecFreq, y = TimeBetweenReadingSessions / 60 / 24)) +
    geom_smooth() +
    geom_point() +
    theme_classic() +
    theme(
        legend.position = "none"
    ) +
    ylab("TimeBetweenReadingSessions (days)")
```

## Create contrasts to predictors

Predictors in the model are given contrasts. Continuous variables are scaled and centered, whereas categorical variables are given helmert contrasts. Helmert contrasts are used to control for uneven levels in categorical variables.

Load a function to create helmert contrasts for categorical variables:

```{r 'load helmert contrasts functions'}
source(
    paste0(
        mypath_SSRBP,
        "/Functions/Functions_contr.helmert.weighted.R"
    )
)
source(
    paste0(
        mypath_SSRBP,
        "/Functions/Functions_contr.helmert.unweighted.R"
    )
)
```

Contrasts for categorical variables:

```{r 'categorical contrasts'}
# whether native language is English or not
reading_frequency_data$NativeEnglish <- as.factor(reading_frequency_data$NativeEnglish)
contrasts(reading_frequency_data$NativeEnglish) <- contr.helmert.unweighted(reading_frequency_data$NativeEnglish)
contrasts(reading_frequency_data$NativeEnglish)
# condition
reading_frequency_data$Condition <- recode(
    reading_frequency_data$Condition,
    "AutonomousCondition" = "HighAutonomyCondition",
    "NonAutonomousCondition" = "LowAutonomyCondition"
)
reading_frequency_data$Condition <- as.factor(reading_frequency_data$Condition)
contrasts(reading_frequency_data$Condition) <- contr.helmert.unweighted(
    reading_frequency_data$Condition
)
contrasts(reading_frequency_data$NativeEnglish)
```

Next, we scale and center continuous variables. These variables names are appended with ".cs" as a reminder that the variable is scaled and centered.

```{r 'scale continuous variables'}
# Situational competence
reading_frequency_data$SCompetence.sc <-
    scale(reading_frequency_data$SCompetence,
        center = TRUE,
        scale = TRUE
    )
# Contextual motivation
reading_frequency_data$CInterest.sc <-
    scale(reading_frequency_data$CInterest,
        center = TRUE,
        scale = TRUE
    )
reading_frequency_data$CCompetence.sc <-
    scale(reading_frequency_data$CCompetence,
        center = TRUE,
        scale = TRUE
    )
# Electronic reading experience
reading_frequency_data$Eexp1LongformEFreq.sc <-
    scale(reading_frequency_data$Eexp1LongformEFreq,
        center = TRUE,
        scale = TRUE
    )
reading_frequency_data$Eexp2DeviceRecFreq.sc <-
    scale(reading_frequency_data$Eexp2DeviceRecFreq,
        center = TRUE,
        scale = TRUE
    )
# Days until reading deadline
reading_frequency_data$DaysUntilDeadline.sc <-
    scale(reading_frequency_data$DaysUntilDeadline,
        center = TRUE,
        scale = TRUE
    )
```

## Model of reading frequency

First, we build the full structure. Refer to the beginning of this script to see information on the full structure. The full model includes 12 parameters (including two random effects and categorical variable levels), and `r nrow(reading_frequency_data)` observations.

```{r}
FullStructure <- (
    "log(TimeBetweenReadingSessions + 2) ~ DaysUntilDeadline.sc + NativeEnglish + Condition + SCompetence.sc + CInterest.sc + CCompetence.sc + Eexp1LongformEFreq.sc + Eexp2DeviceRecFreq.sc +  Eexp1LongformEFreq.sc : Eexp2DeviceRecFreq.sc + (1 | StoryId) + (1 | UserId)"
)
```

```{r}
ReadingFrequency_FullModel <- lmer(FullStructure,
    data = reading_frequency_data,
    control = lmerControl(optimizer = "bobyqa"),
    REML = TRUE
)
```

```{r}
summary(ReadingFrequency_FullModel)
plot(ReadingFrequency_FullModel)
check_model(ReadingFrequency_FullModel)
```

Inspect model values:

```{r}
confint(ReadingFrequency_FullModel)
fixef(ReadingFrequency_FullModel)
```

### Model Assumptions

All models were tested for (1) multicollinearity, (2) non-normality of residuals, (3) heteroscedasticity, (4) influential observations, and (5) normality of random effects

#### 1. Multicollinearity

We check for multicollinearity first with a correlation matrix:

```{r}
corrplot(cor(reading_frequency_data[, c(4:5, 8, 10:13)]), method = "number")
```

Some of the variables show high correlations. For example, 'DaysUntilDeadline' is correlated with the outcome variable 'TimeBetweenReadingSessions' (*r* = `r round(cor(reading_frequency_data$DaysUntilDeadline, reading_frequency_data$TimeBetweenReadingSessions), 2)`), and contextual reading competence is correlated with situational competence (*r* = `r round(cor(reading_frequency_data$SCompetence, reading_frequency_data$CCompetence), 2)`) and contextual motivation (*r* = `r round(cor(reading_frequency_data$CCompetence, reading_frequency_data$CInterest), 2)`).

To check if these correlations are problematic, we calculate Variance Inflation Factors (VIF):

```{r}
check_collinearity(ReadingFrequency_FullModel)
plot(check_collinearity(ReadingFrequency_FullModel))
```

Despite of the correlations, the model predictors do not seem to be multicollinear. All VIF < 2.5, and usually VIF > 5 is used as an indicator of potential multicollinearity.

#### 2. Non-normality of residuals

We first check normality of residuals by plotting model residuals and fitted values

```{r}
plot(resid(ReadingFrequency_FullModel), fitted(ReadingFrequency_FullModel))
```

The plot indicates that the model residuals may be non-normal, because the variables are not scattered symmetrically. It is possible that the 0 values negatively influence non-normality.

To further check non-normality, we use a qqplot:

```{r}
qqnorm(residuals(ReadingFrequency_FullModel))
```

Although plotting residuals against fitted values indicates that there may non-normality, the qqplot shows only slight variation from normality. The non-normality affects extreme values more strongly, possibly due to the skew towards lower values.

Considering that the normality plots show contradicting information, we test normality of residuals with a shapiro test that checks studentized residuals for normal distribution. A p-value of < .05 indicates significant deviation from normality.

```{r}
check_normality(ReadingFrequency_FullModel)
```

The Shapiro test is not significant, indicating that the model is likely to not have non-normal residuals.

#### 3. Heteroscedasticity

We use the Breusch-Pagan test to check whether the variances of residuals in the model vary systematically:

```{r}
check_heteroscedasticity(ReadingFrequency_FullModel)
plot(check_heteroscedasticity(ReadingFrequency_FullModel))
```

The p-value is not significant, which indicates that the residuals are homoscedastic. However, the reference line does not lie flat, indicating that the assumption of homoscedasticity is not met.

We then check each categorical predictor separately with Levene's test:

```{r}
leveneTest(residuals(ReadingFrequency_FullModel) ~ reading_frequency_data$Condition)
```

```{r}
leveneTest(residuals(ReadingFrequency_FullModel) ~ reading_frequency_data$NativeEnglish)
```

The assumption of equal variables is met for both Condition and NativeEnglish.


#### 4. Influential Observations

We test influential observations with Cook's Distance:

```{r}
cooksd <-
    cooks.distance(ReadingFrequency_FullModel)
plot(cooksd,
    pch = "*",
    cex = 2,
    main = "Influential Obs by Cooks Distance"
)
abline(h = 4 * mean(cooksd, na.rm = TRUE), col = "red")
text(
    x = 1:length(cooksd) + 1,
    y = cooksd,
    labels = ifelse(cooksd > 4 * mean(cooksd, na.rm = TRUE), names(cooksd), ""),
    col = "red"
)
```

The plot indicates that two points may be influential: row numbers 56 and 52.
To test the influence of these observations, we re-run the model without each of them:

```{r 'reading frequency model without row number 52'}
reading_frequency_subset <- reading_frequency_data[c(1:51, 53:nrow(reading_frequency_data)), ]
ReadingFrequency_FullModel_Subset <- lmer(FullStructure,
    data = reading_frequency_subset,
    control = lmerControl(optimizer = "bobyqa"),
    REML = TRUE
)
summary(ReadingFrequency_FullModel)
summary(ReadingFrequency_FullModel_Subset)
```

Removal of observation #52 has an impact on the model results, and so this value can be judged as influential and should be removed.

We then assess the removal of #56

```{r}
reading_frequency_subset2 <- reading_frequency_data[c(1:55, 57:nrow(reading_frequency_data)), ]
ReadingFrequency_FullModel_Subset2 <- lmer(FullStructure,
    data = reading_frequency_subset2,
    control = lmerControl(optimizer = "bobyqa"),
    REML = TRUE
)
summary(ReadingFrequency_FullModel)
summary(ReadingFrequency_FullModel_Subset2)
```

Similarly, observation #56 is likely to influence model results. These two observations are removed:

```{r}
reading_frequency_data_without_outliers <-
    reading_frequency_data[c(1:51, 53:55, 57:nrow(reading_frequency_data)), ]
```

The model is re-run at the end of the assumptions testing with the outliers removed dataset.


#### Normality of Random Effects

Random effects should be normally distributed in multilevel models. We test this assumption by inspecting first the normality of 'UserId' and then 'StoryId' random intercepts.

```{r}
random_intercept_UserId <- ranef(ReadingFrequency_FullModel)$UserId$`(Intercept)`
qqnorm(random_intercept_UserId)
qqline(random_intercept_UserId)
shapiro.test(random_intercept_UserId)
```

The qqplot slightly varies from the reference line, but considering that the variance is not extensive and the Shapiro Test is not significant, we assume that UserId random intercept is normally distributed

```{r}
random_intercept_StoryId <- ranef(ReadingFrequency_FullModel)$StoryId$`(Intercept)`
qqnorm(random_intercept_StoryId)
qqline(random_intercept_StoryId)
shapiro.test(random_intercept_StoryId)
```

StoryId aligns much worse with the reference line, however, this is expected considering that StoryId only includes 9 different story groups. With the limited amount of information, achieving a visually normally distributed result is unlikely. Considering that the Shapiro Test is not significant, we can assume that StoryId random intercept is normally distributed.

## Modified Model of Reading Frequency

Considering that we found influential observations, the model is re-fitted:

```{r}
ReadingFrequency_FullModel_Without_Outliers <- lmer(FullStructure,
    data = reading_frequency_data_without_outliers,
    control = lmerControl(optimizer = "bobyqa"),
    REML = TRUE
)
```

The model is singular, and thus it needs to be simplified by backward selection. We remove first the variable which has the lowest p-value. To do this, we inspect model results:

```{r}
summary(ReadingFrequency_FullModel_Without_Outliers)
```

First, we remove contextual motivation 'CInterest.sc':

```{r}
SimplifiedStructure <- str_remove(FullStructure, fixed("+ CInterest.sc "))
```

Fit the simplified model

```{r}
ReadingFrequency_Without_Outliers_Simplified1 <- lmer(
    SimplifiedStructure,
    data = reading_frequency_data_without_outliers,
    control = lmerControl(optimizer = "bobyqa"),
    REML = TRUE
)
```

The model is singular, inspect:

```{r}
summary(ReadingFrequency_Without_Outliers_Simplified1)
```

Next, we remove 'Condition':

```{r}
SimplifiedStructure <- str_remove(SimplifiedStructure, fixed("+ Condition "))
```

fit the model:

```{r}
ReadingFrequency_Without_Outliers_Simplified2 <- lmer(
    SimplifiedStructure,
    data = reading_frequency_data_without_outliers,
    control = lmerControl(optimizer = "bobyqa"),
    REML = TRUE
)
summary(ReadingFrequency_Without_Outliers_Simplified2)
```

The model is singular