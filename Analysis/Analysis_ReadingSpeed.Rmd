---
title: "Analysis_ReadingSpeed"
author: "Pauliina Vuorinen"
date: "14/10/2022-"
output: html_document
library: "~/Extra/RPackages.bib"
---

## Introduction

The purpose of this script is to analyse variance in participants' reading speed.

We aim to assess how variance in reading speed fluctuated during the study, in which contexts, and whether autonomy condition, contextual reading motivation, and electronic reading experience are connected to reading speed. See the full article for details.

To answer these research questions, we use 'ReadingRate' (saved in Data as reading_speed_measure_data.csv) as a measure of variance in reading speed. This measure was computed in Prep_ReadingSpeedMeasure.rmd. The measure indicates the variation in deep reading relative to participants' baseline speed (speed / baseline speed). We focus on 'deep reading' that reflects natural reading speeds with which participants can fully comprehend the story, and thus the dataset only includes observations on deep reading.

In this analysis script, ReadingRate is used as an outcome variable in **two different multilevel models**. In the first model, we study whether reader charactersistics such as condition, contextual motivation, and electronic reading experience predict ReadingRate. In the second model, the independent variables include information on the timing and location of ReadingRate. With the latter model our intention is to study in which situation reading speed varies. Both model structures are based on selection outlined in the full article. The models are constructed using lmer() in the lme4-package by @bates_fitting_2015.

**Information on the hypotheses**

* H5a: Situational autonomous motivation is connected to slower reading speeds when task competence is low, in contrast to situational controlled motivation.
* H5b: Contextual autonomous motivation is connected to slower reading speeds when task competence is low, in contrast to contextual controlled motivation.
* H5c: High levels of task-relevant electronic experience is connected to slower reading speeds when task competence is low.

## Setup

```{r, setup}
library(tidyverse)
library(dplyr)
library(psych)
library(gridExtra)
library(corrplot)
library(lme4)
library(lmerTest)
library(DHARMa)
library(moments)
library(performance)
library(car)
library(effects)
library(interactions)
library(jtools)
getwd() # working directory should be ~/Short_Story_Reading_Behaviour_Public
```

```{r 'figure theme for consistency', echo=FALSE}
figure_theme_with_top_legend <-
    theme_bw() +
    theme(
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        axis.text.x = element_text(size = 10),
        axis.text.y = element_text(size = 10),
        axis.ticks = element_blank(),
        axis.title.x = element_text(size = 10, vjust = 0.5),
        axis.title.y = element_text(size = 10, angle = 90, vjust = 0.5),
        legend.text = element_text(size = 8),
        legend.title = element_text(size = 10),
        legend.key = element_blank(),
        legend.position = "top",
        legend.direction = "horizontal",
        plot.caption = element_text(size = 10),
        strip.text.x = element_text(size = 10),
        legend.background = element_rect(color = "black", size = .5, linetype = "solid")
    )
figure_theme_without_legend_position <-
    theme_bw() +
    theme(
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        axis.text.x = element_text(size = 10),
        axis.text.y = element_text(size = 10),
        axis.ticks = element_blank(),
        axis.title.x = element_text(size = 10, vjust = 0.5),
        axis.title.y = element_text(size = 10, angle = 90, vjust = 0.5),
        legend.text = element_text(size = 8),
        legend.title = element_text(size = 10),
        legend.key = element_blank(),
        plot.caption = element_text(size = 10),
        strip.text.x = element_text(size = 10),
        legend.background = element_rect(color = "black", size = .5, linetype = "solid")
    )
figure_theme_without_legend <-
    theme_bw() +
    theme(
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        axis.text.x = element_text(size = 10),
        axis.text.y = element_text(size = 10),
        axis.ticks = element_blank(),
        axis.title.x = element_text(size = 10, vjust = 0.5),
        axis.title.y = element_text(size = 10, angle = 90, vjust = 0.5),
        legend.key = element_blank(),
        legend.position = "none",
        plot.caption = element_text(size = 10),
        strip.text.x = element_text(size = 10)
    )
```

Save working directory so that this script can be used elsewhere, if required. The working directory should be "~/Short-Story-Reading-Behaviour-Public/". If the working directory is not correct, we save the correct path and use that in loading files. In our purposes, the foulder could be found from /Documents/GITHUB/Short_Story_Reading_Behaviour_Public.

The working directory is not changed with setwd() because this script is knit remotely in other scripts.

```{r 'working directory for my purposes'}
mypath_SSRBP <- getwd()
if (!grepl("Short_Story_Reading_Behaviour_Public", mypath_SSRBP, fixed = TRUE)) {
    # wrong working directory
    if (!grepl("GITHUB", dirname(mypath_SSRBP), fixed = TRUE)) {
        # directory name isn't GITHUB, unlike I would expect
        if (grepl("GITHUB", mypath_SSRBP, fixed = TRUE)) {
            # GITHUB is in the path
            ## use mypath_SSRBP instead of dirname()
            mypath_SSRBP <- paste0(
                mypath_SSRBP,
                "/Short_Story_Reading_Behaviour_Public"
            )
        }
    } else {
        # directory name is GITHUB
        # save correct working directory
        mypath_SSRBP <- paste0(
            dirname(mypath_SSRBP),
            "/Short_Story_Reading_Behaviour_Public"
        )
    }
}
```

## Load data and check variable types

```{r, load data}
# load data
reading_speed_measure_data <-
    read.csv(
        paste0(
            mypath_SSRBP,
            "/Data/reading_speed_measure_data.csv"
        ),
        header = TRUE,
        sep = ";",
        dec = ","
    )
reading_speed_measure_data <- dplyr::select(reading_speed_measure_data, -X) # remove row numbers
```

We then load in data from questionnaires:

```{r 'load predictors: questionnaires'}
# IMI
IMI_scores <-
    read.csv(
        paste0(
            mypath_SSRBP,
            "/Data/IMI_scores.csv"
        ),
        header = TRUE,
        sep = ";",
        dec = ","
    )
IMI_scores <- dplyr::select(IMI_scores, -X) # remove row numbers
# IMI-R
IMIR_scores <-
    read.csv(
        paste0(
            mypath_SSRBP,
            "/Data/IMIR_scores.csv"
        ),
        header = TRUE,
        sep = ";",
        dec = ","
    )
IMIR_scores <- dplyr::select(IMIR_scores, -X) # remove row numbers
# Electronic experience
eexp_scores <-
    read.csv(
        paste0(
            mypath_SSRBP,
            "/Data/eexp_scores.csv"
        ),
        header = TRUE,
        sep = ";",
        dec = ","
    )
eexp_scores <- dplyr::select(eexp_scores, -X) # remove row numbers
# demographic information
demographics_data <-
    read.csv(
        paste0(
            mypath_SSRBP,
            "/Data/demographics_data.csv"
        ),
        header = TRUE,
        sep = ";",
        dec = ","
    )
demographics_data <- dplyr::select(demographics_data, -X) # remove row numbers
```

Load in information about the stories that participants read:

```{r}
story_information_data <-
    read.csv(
        paste0(
            mypath_SSRBP,
            "/Data/story_information_data.csv"
        ),
        header = TRUE,
        sep = ";",
        dec = ","
    )
story_information_data <- dplyr::select(story_information_data, -X) # remove row numbers
```

We then merge these dataframes together:

```{r 'merge dfs'}
# measure and IMI
reading_speed_measure_data <- merge(
    reading_speed_measure_data,
    IMI_scores,
    all.x = TRUE,
    by = "UserId"
)
# measure and IMI-R
reading_speed_measure_data <- merge(
    reading_speed_measure_data,
    IMIR_scores,
    all.x = TRUE,
    by = "UserId"
)
# measure and EEXP
reading_speed_measure_data <- merge(
    reading_speed_measure_data,
    eexp_scores,
    all.x = TRUE,
    by = "UserId"
)
# measure and demographic information
reading_speed_measure_data <- merge(
    reading_speed_measure_data,
    demographics_data,
    all.x = TRUE,
    by = "UserId"
)
# measure and information about stories
reading_speed_measure_data <- merge(
    reading_speed_measure_data,
    story_information_data[, c(1:3, 11)],
    all.x = TRUE,
    by = "StoryId"
)
```

## Change variable types

```{r 'change variable types'}
str(reading_speed_measure_data)
source(
    paste0(
        mypath_SSRBP,
        "/Functions/Functions_VariableTypeConversion.R"
    )
)

## turn columns into factors that should be factors
reading_speed_measure_data[, c(
    "UserId",
    "StoryId"
)] <- convert.magic(
    reading_speed_measure_data[, c(
        "UserId",
        "StoryId"
    )],
    "factor"
)
```

## Reader characteristics model

The reader characteristics model of reading speed aims to address the following hypotheses:

* H5a: Situational autonomous motivation is connected to slower reading speeds when task competence is low, in contrast to situational controlled motivation.
* H5b: Contextual autonomous motivation is connected to slower reading speeds when task competence is low, in contrast to contextual controlled motivation.
* H5c: High levels of task-relevant electronic experience is connected to slower reading speeds when task competence is low.

The reader characteristics model for linearity of reading takes the following structure:

$Y_{i} = 
    \beta_{0} +
    WindowWidth +
    DUD +
    Native +
    Cond +
    SComp +
    CMot +
    CComp +
    EExp1 +
    EExp2 +
    Cond x SComp +
    CMot x SComp +
    EExp1 x EExp2 +
    EExp1 x EExp2 x SComp +
    u_{Subject} +
    u_{Story} +
    \varepsilon_{i}$ 

where
**$Y_{i}$** is the reading behaviour measure, in this case ReadingRate for reading speed. In this outcome variable a value of 1 indicates the participants' baseline reading speed, values below 1 indicate of slower speeds and values above 1 indicate of higher reading speeds. For example, a reading rate of 1.5 indicates that the participant read at 1.5x their baseline speed.
**$\beta_{0}$** is the intercept
**WindowWidth** indicates screen size, measured by window width in pixels (which is affected by device and has an effect on how much text is visible)
**DUD** is an acronym for 'DaysUntilDeadline' which tells us how much the participant has time left to read the short story. Days until deadline is used to control for variance in reading behaviour as a result of pressure to read the short story in time. For example, participants may read the text differently closer to the deadline compared to the beginning of the study.
**Native** is a binary variable indicating whether the participant is a native speaker of English or not (responses - Yes/No, yes indicating that the participant is a native speaker).
**Cond** represents autonomy condition (as a measure of situational motivation)
**SComp** is participants' situational competence (perception of competence to read the story), measured by the subcomponent of 'competence' from the IMI questionnaire (see Prep_Questionnaires.Rmd in Prep folder)
**CMot** is participants' contextual reading motivation, measured by the subcomponent of contextual interest from the IMI-R questionnaire (see Prep_Questionnaires.Rmd in Prep folder)
**CComp** is participants' contextual competence (perception of general reading ability), measured by the subcomponent of 'competence' from the IMI-R questionnaire (see Prep_Questionnaires.Rmd in Prep folder)
**EExp1** is frequency of using any electronic devices for long-form text reading purposes
**EExp2** is frequency of using task-relevant devices for any reading purpose
**$u_{Subject}$** indicates a random intercept of subject indicator
**$u_{Story}$** indicates a random intercept of story indicator
**$\varepsilon_{i}$** indicates the residual variance of $Y_{i}$

Whereas linearity of reading and reading speed are analysed with this reader characteristics structure, the remaining models (task switching and reading persistence) are modelled without 'Cond x SComp', 'CMot x SComp', and 'EExp1 x EExp2 x SComp'. This is because linearity and speed are expected to be connected to motivation and electronic experience via interaction with situational competence, whereas task switching and reading persistence are expected to be connected to motivation and electronic experience directly (main effects).

### Visualise outcome variable and predictors

The reading_speed_measure_data has `r nrow(reading_speed_measure_data)` observations.

We create graphs to inspect speed of reading and its connection to other variables.

ReadingRate is slightly skewed towards lower values, and so it could benefit from a log-transformation:

```{r, include=FALSE}
# hist(reading_speed_measure_data$ReadingRate)
# hist(log(reading_speed_measure_data$ReadingRate + 1))
```

Variance between participants:

```{r, include=FALSE}
ggplot(reading_speed_measure_data, aes(x = UserId, y = ReadingRate)) +
    geom_boxplot() +
    theme_classic()
```

Variance between different stories:

```{r, include=FALSE}
ggplot(reading_speed_measure_data, aes(x = StoryId, y = ReadingRate)) +
    geom_boxplot() +
    theme_classic()
```

We correct for story length to see if there are differences between different books read:

```{r, include=FALSE}
ggplot(reading_speed_measure_data, aes(x = StoryId, y = ReadingRate / CharacterLength)) +
    geom_boxplot() +
    theme_classic()
```

Variance across window widths (size of device and amount of text visible):

```{r, include=FALSE}
ggplot(reading_speed_measure_data, aes(x = WindowWidth, y = ReadingRate)) +
    geom_point() +
    theme_classic()
```

We then visualise the effect of DaysUntilDeadline:

```{r, include=FALSE}
ggplot(reading_speed_measure_data, aes(x = FirstTimeUntilDeadlineDays, y = ReadingRate)) +
    geom_point() +
    theme_classic()
```

### Reading Speed and Demographic Information

Gender:

```{r, include=FALSE}
ggplot(reading_speed_measure_data, aes(x = Gender, y = ReadingRate)) +
    geom_violin() +
    geom_jitter() +
    theme_classic()
```

Age:

```{r, include=FALSE}
ggplot(reading_speed_measure_data, aes(x = Age, y = ReadingRate)) +
    geom_point() +
    theme_classic()
```

Whether participants' native language is English or not:

```{r, include=FALSE}
ggplot(reading_speed_measure_data, aes(x = NativeEnglish, y = ReadingRate)) +
    geom_violin() +
    geom_jitter() +
    theme_classic()
```

### Condition

```{r, include=FALSE}
ggplot(reading_speed_measure_data, aes(x = Condition, y = ReadingRate)) +
    geom_boxplot() +
    theme_classic()
```

### Motivation

Only situational competence is included in the model from the IMI variables, considering that condition is significantly connected to both situational autonomy and interest.

Situational competence:

```{r, include=FALSE}
ggplot(reading_speed_measure_data, aes(x = SCompetence, y = ReadingRate)) +
    geom_smooth() +
    geom_point() +
    theme_classic()
```

We then create visualisations for contextual measures of motivation: interest, and competence.

Contextual interest:

```{r, include=FALSE}
ggplot(reading_speed_measure_data, aes(x = CInterest, y = ReadingRate)) +
    geom_smooth() +
    geom_point() +
    theme_classic()
```

Contextual competence:

```{r, include=FALSE}
ggplot(reading_speed_measure_data, aes(x = CCompetence, y = ReadingRate)) +
    geom_smooth() +
    geom_point() +
    theme_classic()
```

### Reading speed and electronic reading experience

We are interested in how task-relevant electronic experience is connected to reading speed.
Electronic experience was measured by two variables: Eexp1LongFormEFreq - the frequency of reading long-form, narrative texts electronnically, and Eexp2DeviceRecFreq - the frequency of using task-relevant digital devices for recreational reading purposes.

Eexp1LongformEFreq (longfrom reading electronically):

```{r, include=FALSE}
ggplot(reading_speed_measure_data, aes(x = Eexp1LongformEFreq, y = ReadingRate)) +
    geom_point() +
    theme_classic()
```

Eexp2DeviceRecFreq (task-relevant digital devices for recreational reading):

```{r, include=FALSE}
ggplot(reading_speed_measure_data, aes(x = Eexp2DeviceRecFreq, y = ReadingRate)) +
    geom_smooth() +
    geom_point() +
    theme_classic()
```

### Set contrasts to predictors

Predictors in the model are given contrasts. Continuous variables are scaled and centered, whereas categorical variables are given helmert contrasts. Helmert contrasts are used to control for uneven levels in categorical variables.

Load a function to create helmert contrasts for categorical variables:

```{r 'load helmert contrasts functions 1'}
source(
    paste0(
        mypath_SSRBP,
        "/Functions/Functions_contr.helmert.weighted.R"
    )
)
source(
    paste0(
        mypath_SSRBP,
        "/Functions/Functions_contr.helmert.unweighted.R"
    )
)
```

Contrasts for categorical variables:

```{r 'categorical contrasts'}
# whether native language is English or not
reading_speed_measure_data$NativeEnglish <- as.factor(reading_speed_measure_data$NativeEnglish)
contrasts(reading_speed_measure_data$NativeEnglish) <- contr.helmert.unweighted(reading_speed_measure_data$NativeEnglish)
contrasts(reading_speed_measure_data$NativeEnglish)
# condition
reading_speed_measure_data$Condition <- dplyr::recode(
    reading_speed_measure_data$Condition,
    "AutonomousCondition" = "HighAutonomyCondition",
    "NonAutonomousCondition" = "LowAutonomyCondition"
)
reading_speed_measure_data$Condition <- as.factor(reading_speed_measure_data$Condition)
contrasts(reading_speed_measure_data$Condition) <- contr.helmert.unweighted(
    reading_speed_measure_data$Condition
)
contrasts(reading_speed_measure_data$Condition)
```

Next, we scale and center continuous variables. These variables names are appended with ".sc" as a reminder that the variable is scaled and centered.

```{r 'scale continuous variables 1'}
# Situational competence
reading_speed_measure_data$SCompetence.sc <-
    scale(reading_speed_measure_data$SCompetence,
        center = TRUE,
        scale = TRUE
    )
# Contextual motivation
reading_speed_measure_data$CInterest.sc <-
    scale(reading_speed_measure_data$CInterest,
        center = TRUE,
        scale = TRUE
    )
reading_speed_measure_data$CCompetence.sc <-
    scale(reading_speed_measure_data$CCompetence,
        center = TRUE,
        scale = TRUE
    )
# Electronic reading experience
reading_speed_measure_data$Eexp1LongformEFreq.sc <-
    scale(reading_speed_measure_data$Eexp1LongformEFreq,
        center = TRUE,
        scale = TRUE
    )
reading_speed_measure_data$Eexp2DeviceRecFreq.sc <-
    scale(reading_speed_measure_data$Eexp2DeviceRecFreq,
        center = TRUE,
        scale = TRUE
    )
# Days until reading deadline
reading_speed_measure_data$DaysUntilDeadline.sc <-
    scale(reading_speed_measure_data$FirstTimeUntilDeadlineDays,
        center = TRUE,
        scale = TRUE
    )
# Window Width
reading_speed_measure_data$WindowWidth.sc <-
    scale(reading_speed_measure_data$WindowWidth,
        center = TRUE,
        scale = TRUE
    )
```

### Modelling by Reader Characteristics

First, we build the full structure. Refer to the beginning of this script to see information on the full structure. The full model includes 17 parameters (including two random effects and categorical variable levels), and `r nrow(reading_speed_measure_data)` observations. Previous research has suggested that each parameter in a model has at least 20 observations. Our sample exceeds this threshold considering that `r nrow(reading_speed_measure_data)`/17 = `r round(nrow(reading_speed_measure_data)/17, 2)`

```{r}
FullStructure_RC <- (
    "ReadingRate ~ WindowWidth.sc + DaysUntilDeadline.sc + NativeEnglish + Condition + SCompetence.sc + CInterest.sc + CCompetence.sc + Eexp1LongformEFreq.sc + Eexp2DeviceRecFreq.sc +  Condition : SCompetence.sc + CInterest.sc : SCompetence.sc + Eexp1LongformEFreq.sc : Eexp2DeviceRecFreq.sc +  Eexp1LongformEFreq.sc : Eexp2DeviceRecFreq.sc : SCompetence.sc + (1 | StoryId) + (1 | UserId)"
)
```

```{r}
Speed_RC_FullModel <- lmer(
    FullStructure_RC,
    data = reading_speed_measure_data,
    control = lmerControl(optimizer = "bobyqa"),
    REML = TRUE
)
```

The full model converges.

Inspect model values:

```{r, include=FALSE}
summary(Speed_RC_FullModel)
fixef(Speed_RC_FullModel)
# plot(Speed_RC_FullModel)
# plot(reading_speed_measure_data$ReadingRate, fitted(Speed_RC_FullModel))
```

### Model Assumptions

All lmer models were tested for (1) multicollinearity, (2) influential observations, (3) heteroscedasticity, (4) normality of random effects, and (5) normality of random effects

#### 1. Multicollinearity

We check for multicollinearity first with a correlation matrix:

```{r, include=FALSE}
# corrplot(cor(reading_speed_measure_data[, c(31:37)]), method = "number")
```

Some of the variables show high correlations. For example, contextual reading competence is correlated with situational competence (*r* = `r round(cor(reading_speed_measure_data$SCompetence, reading_speed_measure_data$CCompetence), 2)`) and contextual motivation (*r* = `r round(cor(reading_speed_measure_data$CCompetence, reading_speed_measure_data$CInterest), 2)`).

To check if these correlations are problematic, we calculate Variance Inflation Factors (VIF):

```{r, include=FALSE}
check_collinearity(Speed_RC_FullModel)
plot(check_collinearity(Speed_RC_FullModel))
```

Despite of the correlations, the model predictors do not seem to be multicollinear. All VIF < 2, and usually VIF > 5 is used as an indicator of potential multicollinearity.

#### 2. Influential Observations

We test influential observations with Cook's Distance:

```{r, include=FALSE}
# cooksd <-
#     cooks.distance(Speed_RC_FullModel)
# plot(cooksd,
#     pch = "*",
#     cex = 2,
#     main = "Influential Obs by Cooks Distance"
# )
# abline(h = 4 * mean(cooksd, na.rm = TRUE), col = "red")
# text(
#     x = 1:length(cooksd) + 1,
#     y = cooksd,
#     labels = ifelse(cooksd > 4 * mean(cooksd, na.rm = TRUE), names(cooksd), ""),
#     col = "red"
# )
```

The plot indicates that the dataset may include some influential observations. However, the cook's distances are very conservative as the threshold is set at `r 4 * mean(cooksd, na.rm = TRUE)`. Therefore, it is unlikely that these observations influence the model.

To further test influential observations we use performance::check_outliers:

```{r, include=FALSE}
check_outliers(Speed_RC_FullModel)
plot(check_outliers(Speed_RC_FullModel))
```

Although Cook's Distance indicates that the model has influential observations, the outlier test does not produce the same results. Considering the conservative Cook's Distances, we assume that the model does not have influential outliers.

#### 3. Heteroscedasticity

We use the Breusch-Pagan test to check whether the variances of residuals in the model vary systematically:

```{r, include=FALSE}
check_heteroscedasticity(Speed_RC_FullModel)
plot(check_heteroscedasticity(Speed_RC_FullModel))
```

The test is not significant, indicating that the variances are homoscedastic in the model.

We check categorical predictors separately with a Levene's test:

```{r}
leveneTest(residuals(Speed_RC_FullModel) ~ reading_speed_measure_data$Condition)
```

```{r}
leveneTest(residuals(Speed_RC_FullModel) ~ reading_speed_measure_data$NativeEnglish)
```

The Levene's tests indicate that the assumption of equal variances is also met for condition and NativeEnglish.

The model aligns with the assumption of homoscedasticity.

#### 4. Normality of Random Effects

Random effects should be normally distributed in multilevel models. We test this assumption by inspecting first the normality of 'UserId' and then 'StoryId' random intercepts.

```{r, include=FALSE}
random_intercept_UserId <- ranef(Speed_RC_FullModel)$UserId$`(Intercept)`
# qqnorm(random_intercept_UserId)
# qqline(random_intercept_UserId)
shapiro.test(random_intercept_UserId)
```

The qqplot varies slightly from the reference line, however, the Shapiro Test is not significant, and so we assume normality of UserId.

```{r, include=FALSE}
random_intercept_StoryId <- ranef(Speed_RC_FullModel)$StoryId$`(Intercept)`
# qqnorm(random_intercept_StoryId)
# qqline(random_intercept_StoryId)
shapiro.test(random_intercept_StoryId)
```

StoryId aligns much worse with the reference line, however, this is expected considering that StoryId only includes 9 different story groups. With the limited amount of information, achieving a visually normally distributed result is unlikely. Considering that the Shapiro Test is not significant, we can assume that StoryId random intercept is normally distributed.

#### 5. Normality of residuals

We first check normality of residuals by plotting model residuals and fitted values

```{r, include=FALSE}
# plot(resid(Speed_RC_FullModel), fitted(Speed_RC_FullModel))
```

The model residuals are not symmetrically scattered in the plot, as the model observations seem to cluster around specific values.

To further check non-normality, we use a qqplot:

```{r, include=FALSE}
# qqnorm(residuals(Speed_RC_FullModel))
```

The qqplot shows slight variation from normality. However, the variation is not very extensive. Assess normality with a histogram of residuals:

```{r, include=FALSE}
# hist(resid(Speed_RC_FullModel), breaks = 100)
```

The histogram shows a roughly normal distribution. We then inspect skewness and kurtosis in residuals:

```{r, include=FALSE}
# 0 - normal, neg - left skew, pos - right skew
skewness(resid(Speed_RC_FullModel))
# 3 - normal, <3 playkurtic, >3 leptokurtic
kurtosis(resid(Speed_RC_FullModel))
```

The residuals are slightly skewed to the right, and the distribution is slightly leptokurtic.
Finally, we test normality with a Shapiro Wilkins test:

```{r, include=FALSE}
# Shapiro Wilk Test
check_normality(Speed_RC_FullModel)
```

Shapiro Wilk test is significant, indicating of variance from the normal distribution.

However, the visualisations do not raise any significant concerns with normality. Shapiro Wilk test is affected by large sample sizes, and thus the resulting significant p-value may be an indication of a statistically but not practically significant variation from normality due to the large n (*n* = `r nrow(reading_speed_measure_data)`).Furthermore, consultation of resources on mixed modelling indicated that violating the normality of residuals assumption in this case may not be undermine the model quality. For example, @Gelman2007 mention that "the assumption of normality is barely important at all. Thus, [..] we do *not* recommed diagnostics of the normality of regression residuals".

As a result, we assume that the residuals are distributed normally enough for our purposes. 

**Assumptions conclusion**

The model aligns with all assumptions.

### Interpret model

We then interpret model effects to interpret the results.

```{r}
summary(Speed_RC_FullModel)
```

CCompetence (contextual competence), SCompetence:CInterest (an interaction between situational competence and contextual motivation), and SCompetence:Eexp1LongFormEFreq:Eexp2DeviceRecFreq (an interaction between situational competence and the two electronic experience measures) are significant predictors of reading rate.

#### Hypotheses

**H5a: Situational autonomous motivation is connected to slower reading speeds when task competence is low, in contrast to situational controlled motivation.**

This hypothesis was not supported as an interaction effect between Condition and situational competence was not a significant predictor of reading speed in the model.

```{r, include=FALSE}
speed_effect_conditionscomp <- effect(
    "Condition:SCompetence.sc",
    Speed_RC_FullModel
)
plot(speed_effect_conditionscomp,
    multiline = TRUE
)
```

Therefore, our hypothesis H5a was not supported.

Condition was also not a significant predictor in the model, however, it was nearing significance at *p* =  .0577. This trend indicates that participants in the low-autonomy condition were likely to use slightly slower reading speeds compared to participants in the high-autonomy condition, regardless of situational competence:

```{r}
source(
    paste0(
        mypath_SSRBP,
        "/Functions/Functions_AddLine.R"
    )
)
speed_effectplot_condition <- cat_plot(
    Speed_RC_FullModel,
    pred = "Condition",
    pred.labels = c("High-Autonomy Condition", "Low-Autonomy Condition"),
    data =  reading_speed_measure_data,
    plot.points = TRUE,
    point.size = 1,
    point.alpha = .2,
    interval = TRUE,
    point.shape = TRUE
) +
    geom_hline(yintercept = 1, colour = "black") +
    figure_theme_without_legend +
    labs(
        y = "Reading Speed as Proportion of Baseline Speed",
        x = addline_format("Condition,")
    )
```

Therefore, unlike we expected participants' condition assignment and situational competence did not predict reading speed. Instead, a trend in the main effect of condition indicates that participants in the high autonomy condition were slightly more likely to use higher reading speeds than participants in the low-autonomy condition.

**H5b: Contextual autonomous motivation is connected to slower reading speeds when task competence is low, in contrast to contextual controlled motivation.**

An interaction between Contextual motivation (measured by CInterest) and situational competence (SCompetence) was expected to be a significant predictor of reading speed. Indeed, the interaction was significant:

```{r}
speed_effectplot_cmotscomp <- interact_plot(
    Speed_RC_FullModel,
    pred = "SCompetence.sc",
    modx = "CInterest.sc",
    data =  reading_speed_measure_data,
    legend.main = "Contextual motivation score*",
    plot.points = TRUE,
    point.size = 1,
    interval = TRUE,
    point.shape = TRUE
) +
    figure_theme_without_legend_position +
    theme(
        legend.position = c(0.5, .9),
        legend.direction = "vertical"
    ) +
    labs(
        y = "Reading Speed as Proportion of Baseline Speed",
        x = addline_format("Situational competence score,(centered and scaled)")
    )
```

A high contextual motivation score was associated with a baseline-level reading speed regardless of situational competence. However, low situational competence paired with low contextual motivation was connected to faster than usual reading speeds, whereas a high situational competence and low contextual motivation was associated with baseline-level reading speeds.
We would usually assume that readers slow down when the text is difficult to comprehend, but the opposite is seen for participants who are not motivated to read for fun.

Therefore, our hypothesis was supported.

**H5c: High levels of task-relevant electronic experience is connected to slower reading speeds when task competence is low.**

We expected a three-way interaction between situational competence and the two electronic reading experience measures to be a significant predictor of reading speed. Indeed, the interaction effect was significant:

```{r}
speed_effectplot_electronicexperiencescomp <-
    interact_plot(Speed_RC_FullModel,
        pred = SCompetence.sc,
        modx = Eexp2DeviceRecFreq.sc,
        mod2 = Eexp1LongformEFreq.sc,
        data = reading_speed_measure_data,
        plot.points = TRUE,
        point.alpha = .2,
        point.size = 1,
        jitter = .5,
        interval = TRUE,
        legend.main = addline_format("Electronic experience 2"),
        mod2.labels = c("-1SD Electronic Experience 1", "Mean Electronic Experience 1", "+1SD Electronic Experience 1"),
        colors = c("orange", "darkred", "navy"),
        point.shape = TRUE
    ) +
    figure_theme_with_top_legend +
    labs(
        y = "Reading Speed as Proportion of Baseline Speed",
        x = addline_format("Situational competence score,(centered and scaled)")
    )
```

The result indicates that when situational competence is low, a combination of both task-relevant electronic reading experience is associated with a baseline-level reading speed. When situational competence is high, on the other hand, this task-relevant electronic experience is associated with a higher than baseline reading speed. Therefore, task-relevant electronic experience may support participants engagement with the text when competence is low. This finding supports our hypotheses.

Whereas low task-relevant electronic experience (low score in both electronic measures) is connected to a similar patterns (when competence is high, speed tends to be higher than baseline, and when competence is low, speed tends to be baseline-level), a mismatch in electronic experience is associated with different trends. In particular, a low level of experience using task-relevant devices but a high level of experience in reading task-relevant text types electronically is associated with a higher than usual reading speed when competence is low, and a slow reading speed when competence is high. It is possible that participants without device-experience are not aware of device-relevant affordances or they may be more susceptible for shallowing effect than other participants.

#### Other results

In addition, reading speed was significantly predicted by contextual competence (CCompetence.sc).

**Contextual Competence**

```{r}
speed_effectplot_contextualcompetence <- effect_plot(
    Speed_RC_FullModel,
    pred = "CCompetence.sc",
    data =  reading_speed_measure_data,
    plot.points = TRUE,
    point.size = 2,
    interval = TRUE,
    point.shape = TRUE
) +
    figure_theme_with_top_legend +
    labs(
        y = "Reading Speed as Proportion of Baseline Speed",
        x = addline_format("Contextual perceived competence, score (centered and scaled)")
    )
```

Contextual competence is positively linked to reading rate, indicating that a higher perceived reading ability is associated with the tendency to use speeds that are higher than baseline. In contrast, a lower reading ability is connected to baseline-level reading speed.

## Event Properties Model

The event properties model of reading speed is used for explorative purposes, to study how reading speed varied during the study.

The model takes the following structure:

$Y_{i} = 
    \beta_{0} +
    # control variables
    WindowWidth +
    DUD +
    # predictors
    Event~k-1~ +
    Event~k-2~ +
    ReadingSessionNumber +
    TimeInReadingSession +
    LocationInText +
    u_{Subject} +
    u_{Story} +
    \varepsilon_{i}$ 

where
**$Y_{i}$** is the reading behaviour measure, in this case ReadingRate for reading speed (ReadingRate = speed/baseline speed).
**$\beta_{0}$** is the intercept
**WindowWidth** is a continuous measure of screen size, measured by window width in pixels (which is affected by device and has an effect on how much text is visible)
**DUD** is an acronym for 'DaysUntilDeadline' which tells us how much the participant has time left to read the short story. Days until deadline is used to control for variance in reading behaviour as a result of pressure to read the short story in time. For example, participants may read the text differently closer to the deadline compared to the beginning of the study.
**Event~k-1~** reflects the previous ReadingRate event. If the current event is k, then Event k-1 indicates reading rate at k-1
**Event~k-2~** reflects the ReadingRate event preceeding the previous. If the current event is k, then Event k-2 indicates reading rate at k-2
**ReadingSessionNumber**
**TimeInReadingSession**
**LocationInText**
**$u_{Subject}$** indicates a random intercept of subject indicator
**$u_{Story}$** indicates a random intercept of story indicator
**$\varepsilon_{i}$** indicates the residual variance of $Y_{i}$

First, we select the fixed effects in the model backward stepwise until the model converges. We then add two-way interactions in the model, and select them backward stepwise until the model converges. Two-way interactions can be added between predictors measuring previous events (Event~k-1~ and Event~k-2~) and between reading session number, time in reading session, and location in text. To avoid multicollinearity, interactions were not included between between previous events and the other predictors in the model (e.g. Event~k-1~ was not allowed to interact with reading session number, time in reading session, or location in text).

This model selection is used to explore possible interactions that are meaningful to add without overfitting the model.

### Create predictor variables


```{r}
reading_speed_measure_data$Observation_lag1 <- lag(reading_speed_measure_data$ReadingRate, 1)
reading_speed_measure_data$Observation_lag2 <- lag(reading_speed_measure_data$ReadingRate, 2)
```


### Visualise outcome variable and predictors

The reading_speed_measure_data has `r nrow(reading_speed_measure_data)` observations.

We create graphs to inspect linearity of reading and its connection to other variables.
Graphs on the distribution of ReadingRate and connection to UserId, StoryId, DaysUntilDeadline, and WindowWidth were created before the reader characteristics model, and so they are not repeated here.

### Connection to previous event

We visualise connection to previous events to see if reading speed on the previous page, or on the page before the previous, is connected to reading speed on the current page-view.

Previous page-view:

```{r, include=FALSE}
ggplot(
    reading_speed_measure_data,
    aes(x = Observation_lag1, y = ReadingRate)
) +
    geom_point() +
    theme_classic()
```

Two pages before the current page-view:

```{r, include=FALSE}
ggplot(
    reading_speed_measure_data,
    aes(x = Observation_lag2, y = ReadingRate)
) +
    geom_point() +
    theme_classic()
```

### Reading session

Reading session number:

```{r, include=FALSE}
ggplot(
    reading_speed_measure_data,
    aes(x = ReadingSessionNumber, y = ReadingRate)
) +
    geom_jitter() +
    theme_classic()
```

Time in a reading session:

```{r, include=FALSE}
ggplot(
    reading_speed_measure_data,
    aes(x = FirstCumulativeRSTime, y = ReadingRate)
) +
    geom_point() +
    theme_classic() +
    labs(x = "Time in a reading session (min)")
```

Similarly, nonlinearity may be more frequent at the beginning of reading sessions.

### Location in text

```{r}
reading_speed_measure_data$PercentageLocation <- (
    (reading_speed_measure_data$StartLocation
        / reading_speed_measure_data$CharacterLength)
)
```

```{r, include=FALSE}
ggplot(
    reading_speed_measure_data,
    aes(x = PercentageLocation * 100, y = ReadingRate)
) +
    geom_point() +
    theme_classic() +
    labs(x = "Location in text (%)")
```

Reading speed may increase towards the end of the text.

### Set contrasts to predictors

Predictors in the model are given contrasts. Continuous variables are scaled and centered, whereas categorical variables are given helmert contrasts. Helmert contrasts are used to control for uneven levels in categorical variables.

Load a function to create helmert contrasts for categorical variables:

```{r 'load helmert contrasts functions 2'}
source(
    paste0(
        mypath_SSRBP,
        "/Functions/Functions_contr.helmert.weighted.R"
    )
)
source(
    paste0(
        mypath_SSRBP,
        "/Functions/Functions_contr.helmert.unweighted.R"
    )
)
```

We scale and center continuous variables. These variables names are appended with ".cs" as a reminder that the variable is scaled and centered. Note that ReadingSessionNumber is treated as a continuous variable because we do not expect to see categorical differences between reading sessions, on the basis of the visualisations.

```{r 'scale continuous variables 2'}
# Event k-1
reading_speed_measure_data$Observation_lag1.sc <-
    scale(reading_speed_measure_data$Observation_lag1,
        center = TRUE,
        scale = TRUE
    )
# Event k-2
reading_speed_measure_data$Observation_lag2.sc <-
    scale(reading_speed_measure_data$Observation_lag2,
        center = TRUE,
        scale = TRUE
    )
# Window width (control variable)
reading_speed_measure_data$WindowWidth.sc <-
    scale(reading_speed_measure_data$WindowWidth,
        center = TRUE,
        scale = TRUE
    )
# Days until reading deadline (control variable)
reading_speed_measure_data$DaysUntilDeadline.sc <-
    scale(reading_speed_measure_data$FirstTimeUntilDeadlineDays,
        center = TRUE,
        scale = TRUE
    )
# Reading session number
reading_speed_measure_data$ReadingSessionNumber.sc <-
    scale(reading_speed_measure_data$ReadingSessionNumber,
        center = TRUE,
        scale = TRUE
    )
# Time in a reading session
reading_speed_measure_data$TimeInReadingSession.sc <-
    scale(reading_speed_measure_data$FirstCumulativeRSTime,
        center = TRUE,
        scale = TRUE
    )
# Location in text
reading_speed_measure_data$PercentageLocation.sc <-
    scale(reading_speed_measure_data$PercentageLocation,
        center = TRUE,
        scale = TRUE
    )
```

### Modelling by Event Properties

#### Main effects

First, we build the model structure consisting of only main effects and random intercepts. Refer to the beginning of the event properties section of this script to see information on how the model is built.

The model includes 11 parameters before adding interactions, and `r nrow(reading_speed_measure_data)` observations. Previous research has suggested that each parameter in a model has at least 20 observations. Our sample exceeds this threshold considering that `r nrow(reading_speed_measure_data)`/11 = `r round(nrow(reading_speed_measure_data)/11, 2)`

```{r}
AdditiveStructure_EP <- (
    "ReadingRate ~ WindowWidth.sc + DaysUntilDeadline.sc + Observation_lag1.sc + Observation_lag2.sc + ReadingSessionNumber.sc + TimeInReadingSession.sc + PercentageLocation.sc + (1 | StoryId) + (1 | UserId)"
)
```

```{r}
Speed_EP_AdditiveModel <- lmer(
    AdditiveStructure_EP,
    data = reading_speed_measure_data,
    control = lmerControl(optimizer = "bobyqa"),
    REML = TRUE
)
```

The full additive model converges.

```{r, include=FALSE}
summary(Speed_EP_AdditiveModel)
# plot(Speed_EP_AdditiveModel)
```

Inspect model values:

```{r}
fixef(Speed_EP_AdditiveModel)
```

The model with all main effects converges, and so we can add two-way interactions.

#### Interactions

We create a new model structure with interactions between predictors of interest (all main effects apart from DaysUntilDeadline and WindowWidth which are used as control variables only).
Only two-way interactions are included to avoid overfitting the model. No interactions are included between previous events (Observation_lag1 and Observation_lag2) and other predictors in the model (e.g. ReadingSessionNumber) to avoid multicollinearity.

The interactive model includes 15 parameters (including the intercept, main effects, interactions and random effects). Previous research has suggested that each parameter in a model has at least 20 observations. Our sample exceeds this threshold considering that `r nrow(reading_speed_measure_data)`/15 = `r round(nrow(reading_speed_measure_data)/15, 2)`.

```{r}
InteractiveStructure_EP <- (
    "ReadingRate ~ WindowWidth.sc + DaysUntilDeadline.sc + Observation_lag1.sc + Observation_lag2.sc + ReadingSessionNumber.sc + TimeInReadingSession.sc + PercentageLocation.sc + Observation_lag1.sc : Observation_lag2.sc + ReadingSessionNumber.sc : TimeInReadingSession.sc + ReadingSessionNumber.sc : PercentageLocation.sc + TimeInReadingSession.sc : PercentageLocation.sc + (1 | StoryId) + (1 | UserId)"
)
```

```{r}
Speed_EP_InteractiveModel <- lmer(
    InteractiveStructure_EP,
    data = reading_speed_measure_data,
    control = lmerControl(optimizer = "bobyqa"),
    REML = TRUE
)
```

The full interactive model structure converges.

```{r, include=FALSE}
summary(Speed_EP_InteractiveModel)
# plot(Speed_EP_InteractiveModel)
```

Inspect model values:

```{r}
fixef(Speed_EP_InteractiveModel)
```

### Model Assumptions

All linear mixed models were tested for (1) multicollinearity, (2) influential observations, (3) heteroscedasticity, (4) normality of random effects, and (5) normality of residuals.

#### 1. Multicollinearity

We check for multicollinearity first with a correlation matrix:

```{r, include=FALSE}
# corrplot(cor(remove_missing(reading_speed_measure_data[, c(36:37, 41:45)])), method = "number")
```

None of the predictors show high correlations.

We then calculate Variance Inflation Factors (VIF):

```{r, include=FALSE}
check_collinearity(Speed_EP_InteractiveModel)
plot(check_collinearity(Speed_EP_InteractiveModel))
```

The model predictors do not seem to be multicollinear. All VIF < 2, and usually VIF > 5 is used as an indicator of potential multicollinearity.

#### 2. Influential Observations

We test influential observations with Cook's Distance:

```{r, include=FALSE}
# cooksd <-
#     cooks.distance(Speed_EP_InteractiveModel)
# plot(cooksd,
#     pch = "*",
#     cex = 2,
#     main = "Influential Obs by Cooks Distance"
# )
# abline(h = 4 * mean(cooksd, na.rm = TRUE), col = "red")
# text(
#     x = 1:length(cooksd) + 1,
#     y = cooksd,
#     labels = ifelse(cooksd > 4 * mean(cooksd, na.rm = TRUE), names(cooksd), ""),
#     col = "red"
# )
```

The plot indicates that the dataset may include some influential observations. However, the cook's distances are very conservative as the threshold is set at `r 4 * mean(cooksd, na.rm = TRUE)`. Therefore, it is unlikely that these observations influence the model.

To further test influential observations we use performance::check_outliers:

```{r, include=FALSE}
check_outliers(Speed_EP_InteractiveModel)
plot(check_outliers(Speed_EP_InteractiveModel))
```

Although Cook's Distance indicates that the model has influential observations, the outlier test does not produce the same results. Considering the conservative Cook's Distance limit, we assume that the model does not have influential outliers.

#### 3. Heteroscedasticity

We use the Breusch-Pagan test to check whether the variances of residuals in the model vary systematically:

```{r, include=FALSE}
check_heteroscedasticity(Speed_EP_InteractiveModel)
plot(check_heteroscedasticity(Speed_EP_InteractiveModel))
```

The test is not significant, indicating that the variances are homoscedastic in the model.
The model aligns with the assumption of homoscedasticity.

#### 4. Normality of Random Effects

Random effects should be normally distributed in multilevel models. We test this assumption by inspecting first the normality of 'UserId' and then 'StoryId' random intercepts.

```{r, include=FALSE}
random_intercept_UserId <- ranef(Speed_EP_InteractiveModel)$UserId$`(Intercept)`
# qqnorm(random_intercept_UserId)
# qqline(random_intercept_UserId)
shapiro.test(random_intercept_UserId)
```

The qqplot varies slightly from the reference line, however, the Shapiro Test is not significant, and so we assume normality of UserId.

```{r, include=FALSE}
random_intercept_StoryId <- ranef(Speed_EP_InteractiveModel)$StoryId$`(Intercept)`
# qqnorm(random_intercept_StoryId)
# qqline(random_intercept_StoryId)
shapiro.test(random_intercept_StoryId)
```

StoryId aligns much worse with the reference line, however, this is expected considering that StoryId only includes 9 different story groups. With the limited amount of information, achieving a visually normally distributed result is unlikely. Considering that the Shapiro Test is not significant, we can assume that StoryId random intercept is normally distributed.

#### 5. Normality of residuals

We first check normality of residuals by plotting model residuals and fitted values

```{r, include=FALSE}
# plot(resid(Speed_EP_InteractiveModel), fitted(Speed_EP_InteractiveModel))
```

The model residuals are not symmetrically scattered in the plot, as the model observations seem to cluster around specific values.

To further check non-normality, we use a qqplot:

```{r, include=FALSE}
# qqnorm(residuals(Speed_EP_InteractiveModel))
```

The qqplot shows slight variation from normality. However, the variation is not very extensive. Assess normality with a histogram of residuals:

```{r, include=FALSE}
# hist(resid(Speed_EP_InteractiveModel), breaks = 100)
```

The histogram shows a roughly normal distribution. We then inspect skewness and kurtosis in residuals:

```{r}
# 0 - normal, neg - left skew, pos - right skew
skewness(resid(Speed_EP_InteractiveModel))
# 3 - normal, <3 playkurtic, >3 leptokurtic
kurtosis(resid(Speed_EP_InteractiveModel))
```

The residuals are slightly skewed to the right, and the distribution is leptokurtic.
Finally, we test normality with a Shapiro Wilkins test:

```{r, include=FALSE}
# Shapiro Wilk Test
check_normality(Speed_EP_InteractiveModel)
```

Shapiro Wilk test is significant, indicating of variance from the normal distribution.

However, the visualisations do not raise any significant concerns with normality. Shapiro Wilk test is affected by large sample sizes, and thus the resulting significant p-value may be an indication of a statistically but not practically significant variation from normality due to the large n (*n* = `r nrow(reading_speed_measure_data)`).Furthermore, consultation of resources on mixed modelling indicated that violating the normality of residuals assumption in this case may not be undermine the model quality. For example, @Gelman2007 mention that "the assumption of normality is barely important at all. Thus, [..] we do *not* recommed diagnostics of the normality of regression residuals".

As a result, we assume that the residuals are distributed normally enough for our purposes. 

**Assumptions conclusion**

The adapted model aligns with all assumptions.

### Interpret model

We then inspect model effects to interpret the results.

```{r}
summary(Speed_EP_InteractiveModel)
```

In the event properties model, the following variables are significant predictors of reading rate:
(1) Main effect of Observation_lag1 (Event~k-1~)
(2) Main effect of PercentageLocation
(3) Significant interaction effect between ReadingSessionNumber and PercentageLocation
(4) Significant interaction effect between TimeInReadingSession and PercentageLocation

We first inspect the main effect of Observation_lag1 (1), and then the remaining significant effects (2,3,4).

#### Inspect impact of previous event

Observation_lag1 was a significant predictor of reading rate.

```{r}
speed_ep_previouslag1 <- effect_plot(
    Speed_EP_InteractiveModel,
    pred = Observation_lag1.sc,
    plot.points = TRUE,
    point.alpha = .2,
    interval = TRUE
) +
    figure_theme_without_legend +
    labs(
        y = "Reading Speed as Proportion of Baseline Speed",
        x = addline_format("Event~k-1~:,Reading speed on previous page,(centered and scaled)")
    )
```

There is a slight positive trend which indicates that a high reading speed on previous page-view (event k-1) predicts a high reading speed on the following page (event k).

Interestingly, reading speed on the page before the previous (event k-2) was not connected to reading speed (event k).

```{r}
speed_ep_previouslag2 <- effect_plot(
    Speed_EP_InteractiveModel,
    pred = Observation_lag2.sc,
    plot.points = TRUE,
    point.alpha = .2,
    interval = TRUE
) +
    figure_theme_without_legend +
    labs(
        y = "Reading Speed as Proportion of Baseline Speed",
        x = addline_format("Event~k-2~:,Reading speed on the page before previous page,(centered and scaled)")
    )
```

This indicates that variation of reading speed was common - although consecutive pages were likely to be navigated at the same speed, reading speed in event k-2 was not predictive of reading speed in event k.

#### Impact of reading session timing and location in text

In addition to Observation_lag1, reading speed was significantly predicted by PercentageLocation.

```{r}
speed_ep_location <- effect_plot(
    Speed_EP_InteractiveModel,
    pred = PercentageLocation.sc,
    plot.points = TRUE,
    point.alpha = .2,
    interval = TRUE
) +
    figure_theme_without_legend +
    labs(
        y = "Reading Speed as Proportion of Baseline Speed",
        x = "Location in Text (%, centered and scaled)"
    )
```

Location and reading speed were positively correlated, indicating that participants had a tendency to increase their reading speed towards the end of the document.

This main effect was qualified by two significant interactions between PercentageLocation and ReadingSessionNumber, and PercentageLocation and TimeInReadingSession.

First, we inspect the interaction between PercentageLocation and ReadingSessionNumber:

```{r}
speed_ep_locationrsnumb <- interact_plot(
    Speed_EP_InteractiveModel,
    pred = PercentageLocation.sc,
    modx = ReadingSessionNumber.sc,
    legend.main = addline_format("Reading Session,Number*"),
    plot.points = TRUE,
    point.alpha = .2,
    interval = TRUE
) +
    figure_theme_with_top_legend +
    labs(
        y = addline_format("Reading Speed as Proportion,of Baseline Speed"),
        x = addline_format("Location in Text,(%; centered and scaled)")
    )
```

The visualisation indicates that the interaction effect is not particularly strong, as the confidence intervals largely overlap. However, a statistically significant difference is seen between different reading sessions: Early reading sessions have a stronger positive correlation between reading speed and location in text compared to latter reading sessions. Therefore, participants who read most of the text in early reading sessions had a tendency to increase their reading speed towards the end of the text. In contrast, participants who divided their reading in multiple reading sessions, varied their speed less across the text.

However, it is unclear whether the effect is practically significant or simply an artefact of statistical significance due to the high observation count.

We then inspect the interaction effect between PercentageLocation and TimeInReadingSession:

```{r}
speed_ep_locationtimeinrs <- interact_plot(
    Speed_EP_InteractiveModel,
    pred = PercentageLocation.sc,
    modx = TimeInReadingSession.sc,
    legend.main = addline_format("Time in,Reading Session*"),
    plot.points = TRUE,
    point.alpha = .2,
    interval = TRUE
) +
    figure_theme_with_top_legend +
    labs(
        y = "Reading Speed as Proportion of Baseline Speed",
        x = "Location in Text (%, centered and scaled)"
    )
```

Similarly to the interaction between PercentageLocation and ReadingSessionNumber, the effect of PercentageLocation and TimeInReadingSession is minimal. The effect shows that participants who visited the end of the text at the beginning of a reading session were more likely to use faster reading speeds, compared to participants who were at the end of the text at the end of a reading session.

However, it is unclear to what extent the finding is practically significant.