---
title: "Analysis_ReadingSpeed"
author: "Pauliina Vuorinen"
date: "14/10/2022-24/04/2023"
output: html_document
library: ["~/Extra/RPackages.bib", "~/Extra/InCodeCitations.bib"]
csl : ~/Extra/apa-7th-ed.csl
---

## Introduction

The purpose of this script is to analyse variance in participants' reading speed.

We aim to assess how variance in reading speed fluctuated during the study, in which contexts, and whether autonomy condition, contextual reading motivation, and electronic reading experience are connected to reading speed. See the full article for details.

To answer these research questions, we use 'ReadingRate' (saved in Data as reading_speed_measure_data.csv) as a measure of variance in reading speed. This measure was computed in Prep_ReadingSpeedMeasure.rmd. The measure indicates the variation in deep reading relative to participants' baseline speed (speed / baseline speed). We focus on 'deep reading' that reflects natural reading speeds with which participants can fully comprehend the story, and thus the dataset only includes observations on deep reading.

In this analysis script, ReadingRate is used as an outcome variable in **two different multilevel models**. In the first model, we study whether reader charactersistics such as condition, contextual motivation, and electronic reading experience predict ReadingRate. In the second model, the independent variables include information on the timing and location of ReadingRate. With the latter model our intention is to study in which situation reading speed varies. Both model structures are based on selection outlined in the full article. The models are constructed using lmer() in the lme4-package by @bates_fitting_2015.

**Information on the hypotheses**

* H3a: Situational autonomous motivation is connected to slower reading speeds when task competence is low, in contrast to situational controlled motivation.
* H3b: Contextual autonomous motivation is connected to slower reading speeds when task competence is low, in contrast to contextual controlled motivation.
* H3c: High levels of task-relevant electronic experience is connected to slower reading speeds when task competence is low.

## Setup

```{r 'setup', include=FALSE}
library(tidyverse)
library(dplyr)
library(psych)
library(gridExtra)
library(corrplot)
library(lme4)
library(lmerTest)
library(DHARMa)
library(moments)
library(performance)
library(car)
library(effects)
library(interactions)
library(jtools)
```

Save working directory so that this script can be used elsewhere, if required. The working directory should be "~/Short-Story-Reading-Behaviour-Public/". If the working directory is not correct, we save the correct path and use that in loading files.

The working directory is not changed with setwd() because this script is knit remotely in other scripts. If using remotely, define 'AnalysisFilePath'. AnalysisFilePath refers to this exact file location, and so path to the main folder "Short_Story_Reading_Behaviour_Public" is two folders lower.

```{r 'setwd'}
getwd() # working directory should be ~/Short_Story_Reading_Behaviour_Public
# If AnalysisFilePath is not defined, use setwd() to refer to the main folder
# setwd()
if (exists("AnalysisFilePath")) {
    mypath_SSRBP <- dirname(dirname(AnalysisFilePath))
} else if (grepl("Short_Story_Reading_Behaviour_Public/Analysis", getwd())) {
    mypath_SSRBP <- dirname(getwd())
} else if (grepl("Short_Story_Reading_Behaviour_Public", getwd())) {
    mypath_SSRBP <- getwd()
} else {
    print("mypath_SSRBP should be defined manually")
    # mypath_SSRBP <- XX
}
print(mypath_SSRBP)
```

```{r 'load-figure-theme-for-consistency', echo=FALSE, warning="hide"}
source(
    paste0(
        mypath_SSRBP,
        "/Fig/Fig_FigureTheme.R"
    )
)
```

```{r 'load-helmert-contrasts-functions'}
source(
    paste0(
        mypath_SSRBP,
        "/Functions/Functions_contr.helmert.weighted.R"
    )
)
source(
    paste0(
        mypath_SSRBP,
        "/Functions/Functions_contr.helmert.unweighted.R"
    )
)
```

```{r 'source-functions-for-line-adding'}
source(
    paste0(
        mypath_SSRBP,
        "/Functions/Functions_AddLine.R"
    )
)
```

```{r 'source-function-for-variabletype-conversion'}
source(
    paste0(
        mypath_SSRBP,
        "/Functions/Functions_VariableTypeConversion.R"
    )
)
```

## Load data and check variable types

```{r 'load-data'}
# load data
reading_speed_measure_data <-
    read.csv(
        paste0(
            mypath_SSRBP,
            "/Data/reading_speed_measure_data.csv"
        ),
        header = TRUE,
        sep = ";",
        dec = ","
    )
reading_speed_measure_data <- dplyr::select(reading_speed_measure_data, -X) # remove row numbers
```

We then load in data from questionnaires:

```{r 'load-predictors:-questionnaires'}
# IMI
IMI_scores <-
    read.csv(
        paste0(
            mypath_SSRBP,
            "/Data/IMI_scores.csv"
        ),
        header = TRUE,
        sep = ";",
        dec = ","
    )
IMI_scores <- dplyr::select(IMI_scores, -X) # remove row numbers
# IMI-R
IMIR_scores <-
    read.csv(
        paste0(
            mypath_SSRBP,
            "/Data/IMIR_scores.csv"
        ),
        header = TRUE,
        sep = ";",
        dec = ","
    )
IMIR_scores <- dplyr::select(IMIR_scores, -X) # remove row numbers
# Electronic experience
eexp_scores <-
    read.csv(
        paste0(
            mypath_SSRBP,
            "/Data/eexp_scores.csv"
        ),
        header = TRUE,
        sep = ";",
        dec = ","
    )
eexp_scores <- dplyr::select(eexp_scores, -X) # remove row numbers
# demographic information
demographics_data <-
    read.csv(
        paste0(
            mypath_SSRBP,
            "/Data/demographics_data.csv"
        ),
        header = TRUE,
        sep = ";",
        dec = ","
    )
demographics_data <- dplyr::select(demographics_data, -X) # remove row numbers
```

Load in information about the stories that participants read:

```{r 'load-information-about-stories'}
story_information_data <-
    read.csv(
        paste0(
            mypath_SSRBP,
            "/Data/story_information_data.csv"
        ),
        header = TRUE,
        sep = ";",
        dec = ","
    )
story_information_data <- dplyr::select(story_information_data, -X) # remove row numbers
```

We then merge these dataframes together:

```{r 'merge-dfs'}
# measure and IMI
reading_speed_measure_data <- merge(
    reading_speed_measure_data,
    IMI_scores,
    all.x = TRUE,
    by = "UserId"
)
# measure and IMI-R
reading_speed_measure_data <- merge(
    reading_speed_measure_data,
    IMIR_scores,
    all.x = TRUE,
    by = "UserId"
)
# measure and EEXP
reading_speed_measure_data <- merge(
    reading_speed_measure_data,
    eexp_scores,
    all.x = TRUE,
    by = "UserId"
)
# measure and demographic information
reading_speed_measure_data <- merge(
    reading_speed_measure_data,
    demographics_data,
    all.x = TRUE,
    by = "UserId"
)
# measure and information about stories
reading_speed_measure_data <- merge(
    reading_speed_measure_data,
    story_information_data[, c(1:3, 8)],
    all.x = TRUE,
    by = "StoryId"
)
```

## Change variable types

```{r 'change-variable-types'}
str(reading_speed_measure_data)

## turn columns into factors that should be factors
reading_speed_measure_data[, c(
    "UserId",
    "StoryId"
)] <- convert.magic(
    reading_speed_measure_data[, c(
        "UserId",
        "StoryId"
    )],
    "factor"
)
```

## Reader characteristics model

The reader characteristics model of reading speed aims to address the following hypotheses:

* H3a: Situational autonomous motivation is connected to slower reading speeds when task competence is low, in contrast to situational controlled motivation.
* H3b: Contextual autonomous motivation is connected to slower reading speeds when task competence is low, in contrast to contextual controlled motivation.
* H3c: High levels of task-relevant electronic experience is connected to slower reading speeds when task competence is low.

The reader characteristics model was pre-specified to best address our hypotheses. We use a maximal interactive model structure, which includes random intercepts for story and participant indicator. Random slopes were included for all key variables in the model which are used to address our hypotheses. These random slopes could only be included in the random effect of story indicator, considering that all key variables had only one observation from each participant.

The maximal interactive model takes the following structure:

$Y_{i} = 
    \beta_{0} +
    WindowWidth +
    DUD +
    Native +
    Cond +
    SComp +
    CMot +
    CComp +
    TR-EExp1 +
    TR-EExp2 +
    Cond x SComp +
    CMot x SComp +
    TR-EExp1 x TR-EExp2 +
    TR-EExp1 x TR-EExp2 x SComp +
    (1  + Cond x SComp + CMot x SComp + TR-EEXP1 x TR-EEXP2 | Story indicator) +
    (1 | Participant indicator) +
    \varepsilon_{i}$

where
**$Y_{i}$** is the reading behaviour measure, in this case ReadingRate for reading speed. In this outcome variable a value of 1 indicates the participants' baseline reading speed, values below 1 indicate of slower speeds and values above 1 indicate of higher reading speeds. For example, a reading rate of 1.5 indicates that the participant read at 1.5x their baseline speed.
**$\beta_{0}$** is the intercept
**WindowWidth** indicates screen size, measured by window width in pixels (which is affected by device and has an effect on how much text is visible)
**DUD** is an acronym for 'DaysUntilDeadline' which tells us how much the participant has time left to read the short story. Days until deadline is used to control for variance in reading behaviour as a result of pressure to read the short story in time. For example, participants may read the text differently closer to the deadline compared to the beginning of the study.
**Native** is a binary variable indicating whether the participant is a native speaker of English or not (responses - Yes/No, yes indicating that the participant is a native speaker).
**Cond** represents autonomy condition (as a measure of situational motivation)
**SComp** is participants' situational competence (perception of competence to read the story), measured by the subcomponent of 'competence' from the IMI questionnaire (see Prep_Questionnaires.Rmd in Prep folder)
**CMot** is participants' contextual reading motivation, measured by the subcomponent of contextual interest from the IMI-R questionnaire (see Prep_Questionnaires.Rmd in Prep folder)
**CComp** is participants' contextual competence (perception of general reading ability), measured by the subcomponent of 'competence' from the IMI-R questionnaire (see Prep_Questionnaires.Rmd in Prep folder)
**TR-EExp1** is frequency of using any electronic devices for long-form text reading purposes
**TR-EExp2** is frequency of using task-relevant devices for any reading purpose
**(1  + Cond x SComp + CMot x SComp + TR-EEXP1 x TR-EEXP2 | Story indicator)** indicates a random effect of story indicator. The random effect includes an intercept for each story indicator, and a random slope for all key variables used to address our hypotheses.
**(1 | Participant indicator)** indicates a random effect of participant indicator. The random effect only includes the random intercept for each participant considering that key variables of interest only had one observation for each participant, and so usage of random slopes was not meaningful. Note that participant indicator is explicitly nested within story indicator as participants only read one of 9 stories during the study. Due to the explicit nesting, notation as nested vs crossed does not make a difference in the model specification. To allow us to use different random slopes, we use crossed random effect notation here.
**$\varepsilon_{i}$** indicates the residual variance of $Y_{i}$

Whereas linearity of reading and reading speed are analysed with this reader characteristics structure, the remaining models (task switching and reading persistence) are modelled without 'Cond x SComp', 'CMot x SComp', and 'TR-EExp1 x TR-EExp2 x SComp'. This is because linearity and speed are expected to be connected to motivation and electronic experience via interaction with situational competence, whereas task switching and reading persistence are expected to be connected to motivation and electronic experience directly (main effects).

In case of nonconvergence or singularity, the model is selected backward stepwise. This is done by first removing random slopes from the model starting with the slope that accounts for the least variance. If the model remains nonconvergent or singular, fixed effects are removed one-by-one starting with the predictors that account for the least variance according to p-values.

### Visualise outcome variable and predictors

The reading_speed_measure_data has `r nrow(reading_speed_measure_data)` observations.

We create graphs to inspect speed of reading and its connection to other variables.

ReadingRate is slightly skewed towards lower values, and so it could benefit from a log-transformation:

```{r, eval=FALSE, include=FALSE}
# hist(reading_speed_measure_data$ReadingRate)
# hist(log(reading_speed_measure_data$ReadingRate + 1))
```

Variance between participants:

```{r, include=FALSE}
ggplot(reading_speed_measure_data, aes(x = UserId, y = ReadingRate)) +
    geom_boxplot() +
    theme_classic()
```

Variance between different stories:

```{r, include=FALSE}
ggplot(reading_speed_measure_data, aes(x = StoryId, y = ReadingRate)) +
    geom_boxplot() +
    theme_classic()
```

We correct for story length to see if there are differences between different books read:

```{r, include=FALSE}
ggplot(reading_speed_measure_data, aes(x = StoryId, y = ReadingRate / CharacterLength)) +
    geom_boxplot() +
    theme_classic()
```

Variance across window widths (size of device and amount of text visible):

```{r, include=FALSE}
ggplot(reading_speed_measure_data, aes(x = WindowWidth, y = ReadingRate)) +
    geom_point() +
    theme_classic()
```

We then visualise the effect of DaysUntilDeadline:

```{r, include=FALSE}
ggplot(reading_speed_measure_data, aes(x = FirstTimeUntilDeadlineDays, y = ReadingRate)) +
    geom_point() +
    theme_classic()
```

### Reading Speed and Demographic Information

Gender:

```{r, include=FALSE}
ggplot(reading_speed_measure_data, aes(x = Gender, y = ReadingRate)) +
    geom_violin() +
    geom_jitter() +
    theme_classic()
```

Age:

```{r, include=FALSE}
ggplot(reading_speed_measure_data, aes(x = Age, y = ReadingRate)) +
    geom_point() +
    theme_classic()
```

Whether participants' native language is English or not:

```{r, include=FALSE}
ggplot(reading_speed_measure_data, aes(x = NativeEnglish, y = ReadingRate)) +
    geom_violin() +
    geom_jitter() +
    theme_classic()
```

### Condition

```{r, include=FALSE}
ggplot(reading_speed_measure_data, aes(x = Condition, y = ReadingRate)) +
    geom_boxplot() +
    theme_classic()
```

### Motivation

Only situational competence is included in the model from the IMI variables, considering that condition is significantly connected to both situational autonomy and interest.

Situational competence:

```{r, include=FALSE}
ggplot(reading_speed_measure_data, aes(x = SCompetence, y = ReadingRate)) +
    geom_smooth() +
    geom_point() +
    theme_classic()
```

We then create visualisations for contextual measures of motivation: interest, and competence.

Contextual interest:

```{r, include=FALSE}
ggplot(reading_speed_measure_data, aes(x = CInterest, y = ReadingRate)) +
    geom_smooth() +
    geom_point() +
    theme_classic()
```

Contextual competence:

```{r, include=FALSE}
ggplot(reading_speed_measure_data, aes(x = CCompetence, y = ReadingRate)) +
    geom_smooth() +
    geom_point() +
    theme_classic()
```

### Reading speed and electronic reading experience

We are interested in how task-relevant electronic experience is connected to reading speed.
Electronic experience was measured by two variables: Eexp1LongFormEFreq - the frequency of reading long-form, narrative texts electronnically, and Eexp2DeviceRecFreq - the frequency of using task-relevant digital devices for recreational reading purposes.

Eexp1LongformEFreq (longfrom reading electronically):

```{r, include=FALSE}
ggplot(reading_speed_measure_data, aes(x = Eexp1LongformEFreq, y = ReadingRate)) +
    geom_point() +
    theme_classic()
```

Eexp2DeviceRecFreq (task-relevant digital devices for recreational reading):

```{r, include=FALSE}
ggplot(reading_speed_measure_data, aes(x = Eexp2DeviceRecFreq, y = ReadingRate)) +
    geom_smooth() +
    geom_point() +
    theme_classic()
```

### Set contrasts to predictors

Predictors in the model are given contrasts. Continuous variables are scaled and centered, whereas categorical variables are given helmert contrasts. Helmert contrasts are used to control for uneven levels in categorical variables.

Contrasts for categorical variables:

```{r 'categorical-contrasts', echo=FALSE}
# whether native language is English or not
reading_speed_measure_data$NativeEnglish <- as.factor(reading_speed_measure_data$NativeEnglish)
contrasts(reading_speed_measure_data$NativeEnglish) <- contr.helmert.unweighted(reading_speed_measure_data$NativeEnglish)
contrasts(reading_speed_measure_data$NativeEnglish)
# condition
reading_speed_measure_data$Condition <- dplyr::recode(
    reading_speed_measure_data$Condition,
    "AutonomousCondition" = "HighAutonomyCondition",
    "NonAutonomousCondition" = "LowAutonomyCondition"
)
reading_speed_measure_data$Condition <- as.factor(reading_speed_measure_data$Condition)
contrasts(reading_speed_measure_data$Condition) <- contr.helmert.unweighted(
    reading_speed_measure_data$Condition
)
contrasts(reading_speed_measure_data$Condition)
```

Next, we scale and center continuous variables. These variables names are appended with ".sc" as a reminder that the variable is scaled and centered.

```{r 'scale-continuous-variables-1', echo=FALSE}
# Situational competence
reading_speed_measure_data$SCompetence.sc <-
    scale(reading_speed_measure_data$SCompetence,
        center = TRUE,
        scale = TRUE
    )
# Contextual motivation
reading_speed_measure_data$CInterest.sc <-
    scale(reading_speed_measure_data$CInterest,
        center = TRUE,
        scale = TRUE
    )
reading_speed_measure_data$CCompetence.sc <-
    scale(reading_speed_measure_data$CCompetence,
        center = TRUE,
        scale = TRUE
    )
# Electronic reading experience
reading_speed_measure_data$Eexp1LongformEFreq.sc <-
    scale(reading_speed_measure_data$Eexp1LongformEFreq,
        center = TRUE,
        scale = TRUE
    )
reading_speed_measure_data$Eexp2DeviceRecFreq.sc <-
    scale(reading_speed_measure_data$Eexp2DeviceRecFreq,
        center = TRUE,
        scale = TRUE
    )
# Days until reading deadline
reading_speed_measure_data$DaysUntilDeadline.sc <-
    scale(reading_speed_measure_data$FirstTimeUntilDeadlineDays,
        center = TRUE,
        scale = TRUE
    )
# Window Width
reading_speed_measure_data$WindowWidth.sc <-
    scale(reading_speed_measure_data$WindowWidth,
        center = TRUE,
        scale = TRUE
    )
```

### Modelling by Reader Characteristics

First, we build the maximal interactive model structure. The maximal model includes XX parameters, and `r nrow(reading_speed_measure_data)` observations. Previous research has suggested that each parameter in a model has at least 15 observations. Our sample exceeds this threshold considering that `r nrow(reading_speed_measure_data)`/16 = `r round(nrow(reading_speed_measure_data)/16, 2)`

```{r 'define-maximal-model-structure'}
Structure_RC_nested_maximal <- (
    "ReadingRate ~ WindowWidth.sc + DaysUntilDeadline.sc + NativeEnglish + Condition + SCompetence.sc + CInterest.sc + CCompetence.sc + Eexp1LongformEFreq.sc + Eexp2DeviceRecFreq.sc +  Condition : SCompetence.sc + CInterest.sc : SCompetence.sc + Eexp1LongformEFreq.sc : Eexp2DeviceRecFreq.sc +  Eexp1LongformEFreq.sc : Eexp2DeviceRecFreq.sc : SCompetence.sc + (1 + Condition : SCompetence.sc + CInterest.sc : SCompetence.sc +  Eexp1LongformEFreq.sc : Eexp2DeviceRecFreq.sc : SCompetence.sc | StoryId) + (1  | UserId)"
)
```

```{r 'run-maximal-model', warning='hide'}
Speed_RC_nested_maximal <- lmer(
    Structure_RC_nested_maximal,
    data = reading_speed_measure_data,
    control = lmerControl(optimizer = "bobyqa"),
    REML = TRUE
)
```

The maximal model is singular. We attempt to resolve this by backward stepwise selection of the random slopes.

```{r 'backward-stepwise-select-slopes', eval=FALSE}
# Identify slope that accounts for the least variance
summary(Speed_RC_nested_maximal) # SCompetence : CInterest
# Remove SCompetence : CInterest random slope and refit the model
Structure_RC_nested_selected1 <- (
    "ReadingRate ~ WindowWidth.sc + DaysUntilDeadline.sc + NativeEnglish + Condition + SCompetence.sc + CInterest.sc + CCompetence.sc + Eexp1LongformEFreq.sc + Eexp2DeviceRecFreq.sc +  Condition : SCompetence.sc + CInterest.sc : SCompetence.sc + Eexp1LongformEFreq.sc : Eexp2DeviceRecFreq.sc +  Eexp1LongformEFreq.sc : Eexp2DeviceRecFreq.sc : SCompetence.sc + (1 + Condition : SCompetence.sc +  Eexp1LongformEFreq.sc : Eexp2DeviceRecFreq.sc : SCompetence.sc | StoryId) + (1  | UserId)"
)
Speed_RC_nested_selected1 <- lmer( # remains singular
    Structure_RC_nested_selected1,
    data = reading_speed_measure_data,
    control = lmerControl(optimizer = "bobyqa"),
    REML = TRUE
)
# Identify slope that accounts for the least variance
summary(Speed_RC_nested_selected1) # SCompetence : TR-EEXP1 : TR-EEXP2
# Remove SCompetence : TR-EEXP1 : TR-EEXP2 random slope and refit the model
Structure_RC_nested_selected2 <- (
    "ReadingRate ~ WindowWidth.sc + DaysUntilDeadline.sc + NativeEnglish + Condition + SCompetence.sc + CInterest.sc + CCompetence.sc + Eexp1LongformEFreq.sc + Eexp2DeviceRecFreq.sc +  Condition : SCompetence.sc + CInterest.sc : SCompetence.sc + Eexp1LongformEFreq.sc : Eexp2DeviceRecFreq.sc +  Eexp1LongformEFreq.sc : Eexp2DeviceRecFreq.sc : SCompetence.sc + (1 + Condition : SCompetence.sc | StoryId) + (1  | UserId)"
)
Speed_RC_nested_selected2 <- lmer( # remains singular, nc
    Structure_RC_nested_selected2,
    data = reading_speed_measure_data,
    control = lmerControl(optimizer = "bobyqa"),
    REML = TRUE
)
# Remove final random slope
Structure_RC_nested_selected3 <- (
    "ReadingRate ~ WindowWidth.sc + DaysUntilDeadline.sc + NativeEnglish + Condition + SCompetence.sc + CInterest.sc + CCompetence.sc + Eexp1LongformEFreq.sc + Eexp2DeviceRecFreq.sc +  Condition : SCompetence.sc + CInterest.sc : SCompetence.sc + Eexp1LongformEFreq.sc : Eexp2DeviceRecFreq.sc +  Eexp1LongformEFreq.sc : Eexp2DeviceRecFreq.sc : SCompetence.sc + (1 | StoryId) + (1  | UserId)"
)
Speed_RC_nested_selected3 <- lmer(
    Structure_RC_nested_selected3,
    data = reading_speed_measure_data,
    control = lmerControl(optimizer = "bobyqa"),
    REML = TRUE
)
```

The model converges and is no longer singular after removal of all random slopes.
Inspect the model:

```{r, include=FALSE, warning='hide'}
Structure_RC_nested_selected3 <- (
    "ReadingRate ~ WindowWidth.sc + DaysUntilDeadline.sc + NativeEnglish + Condition + SCompetence.sc + CInterest.sc + CCompetence.sc + Eexp1LongformEFreq.sc + Eexp2DeviceRecFreq.sc +  Condition : SCompetence.sc + CInterest.sc : SCompetence.sc + Eexp1LongformEFreq.sc : Eexp2DeviceRecFreq.sc +  Eexp1LongformEFreq.sc : Eexp2DeviceRecFreq.sc : SCompetence.sc + (1 | StoryId) + (1  | UserId)"
)
Speed_RC_nested_selected3 <- lmer(
    Structure_RC_nested_selected3,
    data = reading_speed_measure_data,
    control = lmerControl(optimizer = "bobyqa"),
    REML = TRUE
)
summary(Speed_RC_nested_selected3)
fixef(Speed_RC_nested_selected3)
plot(Speed_RC_nested_selected3)
```

We then proceed to testing assumptions:

### Model Assumptions

All lmer models were tested for (1) multicollinearity, (2) influential observations, (3) heteroscedasticity, and (4) normality of random effects

#### 1. Multicollinearity

We check for multicollinearity first with a correlation matrix:

```{r, eval=FALSE, include=FALSE}
# corrplot(cor(reading_speed_measure_data[, c(31:37)]), method = "number")
```

Some of the variables show high correlations. For example, contextual reading competence is correlated with situational competence (*r* = `r round(cor(reading_speed_measure_data$SCompetence, reading_speed_measure_data$CCompetence), 2)`) and contextual motivation (*r* = `r round(cor(reading_speed_measure_data$CCompetence, reading_speed_measure_data$CInterest), 2)`).

To check if these correlations are problematic, we calculate Variance Inflation Factors (VIF):

```{r, eval=FALSE, include=FALSE}
check_collinearity(Speed_RC_nested_selected3)
plot(check_collinearity(Speed_RC_nested_selected3))
```

Despite of the correlations, the model predictors do not seem to be multicollinear. All VIF < 2, and usually VIF > 5 is used as an indicator of potential multicollinearity.

#### 2. Influential Observations

We test influential observations with Cook's Distance:

```{r}
cooksd <-
    cooks.distance(Speed_RC_nested_selected3)
```

```{r, eval=FALSE, include=FALSE}
# plot(cooksd,
#     pch = "*",
#     cex = 2,
#     main = "Influential Obs by Cooks Distance"
# )
# abline(h = 4 * mean(cooksd, na.rm = TRUE), col = "red")
# text(
#     x = 1:length(cooksd) + 1,
#     y = cooksd,
#     labels = ifelse(cooksd > 4 * mean(cooksd, na.rm = TRUE), names(cooksd), ""),
#     col = "red"
# )
```

The plot indicates that the dataset may include some influential observations. However, the cook's distances are very conservative as the threshold is set at `r 4 * mean(cooksd, na.rm = TRUE)`. Therefore, it is unlikely that these observations influence the model.

To further test influential observations we use performance::check_outliers:

```{r, eval=FALSE, include=FALSE}
check_outliers(Speed_RC_nested_selected3)
plot(check_outliers(Speed_RC_nested_selected3))
```

Although Cook's Distance indicates that the model has influential observations, the outlier test does not produce the same results. Considering the conservative Cook's Distances, we assume that the model does not have influential outliers.

#### 3. Heteroscedasticity

We use the Breusch-Pagan test to check whether the variances of residuals in the model vary systematically:

```{r, eval=FALSE, include=FALSE}
check_heteroscedasticity(Speed_RC_nested_selected3)
plot(check_heteroscedasticity(Speed_RC_nested_selected3))
```

The test is not significant, indicating that the variances are homoscedastic in the model.

We check categorical predictors separately with a Levene's test:

```{r, eval=FALSE}
leveneTest(residuals(Speed_RC_nested_selected3) ~ reading_speed_measure_data$Condition)
```

```{r, eval=FALSE}
leveneTest(residuals(Speed_RC_nested_selected3) ~ reading_speed_measure_data$NativeEnglish)
```

The Levene's tests indicate that the assumption of equal variances is also met for condition and NativeEnglish.

The model aligns with the assumption of homoscedasticity.

#### 4. Normality of Random Effects

Random effects should be normally distributed in multilevel models. We test this assumption by inspecting first the normality of 'UserId' and then 'StoryId' random intercepts.

```{r, eval=FALSE, include=FALSE}
random_intercept_UserId <- ranef(Speed_RC_nested_selected3)$UserId$`(Intercept)`
# qqnorm(random_intercept_UserId)
# qqline(random_intercept_UserId)
shapiro.test(random_intercept_UserId)
```

The qqplot varies slightly from the reference line, however, the Shapiro Test is not significant, and so we assume normality of UserId.

```{r, eval=FALSE, include=FALSE}
random_intercept_StoryId <- ranef(Speed_RC_nested_selected3)$StoryId$`(Intercept)`
# qqnorm(random_intercept_StoryId)
# qqline(random_intercept_StoryId)
shapiro.test(random_intercept_StoryId)
```

StoryId aligns much worse with the reference line, however, this is expected considering that StoryId only includes 9 different story groups. With the limited amount of information, achieving a visually normally distributed result is unlikely. Considering that the Shapiro Test is not significant, we can assume that StoryId random intercept is normally distributed.

#### 5. Normality of residuals

We first check normality of residuals by plotting model residuals and fitted values

```{r, eval=FALSE, include=FALSE}
# plot(resid(Speed_RC_nested_selected3), fitted(Speed_RC_nested_selected3))
```

The model residuals are not symmetrically scattered in the plot, as the model observations seem to cluster around specific values.

To further check non-normality, we use a qqplot:

```{r, eval=FALSE, include=FALSE}
# qqnorm(residuals(Speed_RC_nested_selected3))
```

The qqplot shows slight variation from normality. However, the variation is not very extensive. Assess normality with a histogram of residuals:

```{r, eval=FALSE, include=FALSE}
# hist(resid(Speed_RC_nested_selected3), breaks = 100)
```

The histogram shows a roughly normal distribution. We then inspect skewness and kurtosis in residuals:

```{r, eval=FALSE, include=FALSE}
# 0 - normal, neg - left skew, pos - right skew
skewness(resid(Speed_RC_nested_selected3))
# 3 - normal, <3 playkurtic, >3 leptokurtic
kurtosis(resid(Speed_RC_nested_selected3))
```

The residuals are slightly skewed to the right, and the distribution is slightly leptokurtic.
Finally, we test normality with a Shapiro Wilkins test:

```{r, eval=FALSE, include=FALSE}
# Shapiro Wilk Test
check_normality(Speed_RC_nested_selected3)
```

Shapiro Wilk test is significant, indicating of variance from the normal distribution.

However, the visualisations do not raise any significant concerns with normality. Shapiro Wilk test is affected by large sample sizes, and thus the resulting significant p-value may be an indication of a statistically but not practically significant variation from normality due to the large n (*n* = `r nrow(reading_speed_measure_data)`).Furthermore, consultation of resources on mixed modelling indicated that violating the normality of residuals assumption in this case may not be undermine the model quality. For example, @gelman_data_2007 mention that "the assumption of normality is barely important at all. Thus, [..] we do *not* recommed diagnostics of the normality of regression residuals".

As a result, we assume that the residuals are distributed normally enough for our purposes. 

**Assumptions conclusion**

The model aligns with all assumptions.

### Interpret model

We then interpret model effects to study the results.

```{r, include=FALSE}
summary(Speed_RC_nested_selected3)
```

Significant predictors of reading rate:

* CCompetence (contextual competence),
* SCompetence:CInterest (an interaction between situational competence and contextual motivation), and
* SCompetence:Eexp1LongFormEFreq:Eexp2DeviceRecFreq (an interaction between situational competence and the two electronic experience measures)

#### Hypotheses

**H3a: Situational autonomous motivation is connected to slower reading speeds when task competence is low, in contrast to situational controlled motivation.**

This hypothesis was not supported as an interaction effect between Condition and situational competence was not a significant predictor of reading speed in the model.

```{r, include=FALSE}
speed_effect_conditionscomp <- effect(
    "Condition:SCompetence.sc",
    Speed_RC_nested_selected3
)
plot(speed_effect_conditionscomp,
    multiline = TRUE
)
```

Therefore, our hypothesis H3a was not supported.

Condition was also not a significant predictor in the model, however, it was nearing significance at *p* =  .0577. This trend indicates that participants in the low-autonomy condition were likely to use slightly slower reading speeds compared to participants in the high-autonomy condition, regardless of situational competence:

```{r, warning='hide'}
speed_effectplot_condition <- cat_plot(
    Speed_RC_nested_selected3,
    pred = "Condition",
    pred.labels = c("High-Autonomy Condition", "Low-Autonomy Condition"),
    data =  reading_speed_measure_data,
    plot.points = TRUE,
    point.size = 1,
    point.alpha = .2,
    interval = TRUE,
    point.shape = TRUE
) +
    geom_hline(yintercept = 1, colour = "black") +
    figure_theme_without_legend +
    labs(
        y = "Reading Speed as Proportion of Baseline Speed",
        x = addline_format("Condition,")
    )
```

Therefore, unlike we expected participants' condition assignment and situational competence did not predict reading speed. Instead, a trend in the main effect of condition indicates that participants in the high autonomy condition were slightly more likely to use higher reading speeds than participants in the low-autonomy condition.

**H3b: Contextual autonomous motivation is connected to slower reading speeds when task competence is low, in contrast to contextual controlled motivation.**

An interaction between Contextual motivation (measured by CInterest) and situational competence (SCompetence) was expected to be a significant predictor of reading speed. Indeed, the interaction was significant:

```{r, warning='hide'}
speed_effectplot_cmotscomp <- interact_plot(
    Speed_RC_nested_selected3,
    pred = "SCompetence.sc",
    modx = "CInterest.sc",
    data =  reading_speed_measure_data,
    legend.main = addline_format("Contextual,motivation score"),
    plot.points = TRUE,
    point.size = 1,
    point.alpha = .2,
    interval = TRUE,
    point.shape = TRUE
) +
    figure_theme_with_top_legend +
    labs(
        y = addline_format("Reading Speed as Proportion,of Baseline Speed"),
        x = addline_format("Situational competence score,(centered and scaled)")
    )
```

A high contextual motivation score was associated with a baseline-level reading speed regardless of situational competence. However, low situational competence paired with low contextual motivation was connected to faster than usual reading speeds, whereas a high situational competence and low contextual motivation was associated with baseline-level reading speeds.
We would usually assume that readers slow down when the text is difficult to comprehend, but the opposite is seen for participants who are not motivated to read for fun.

Therefore, our hypothesis was supported.

**H3c: High levels of task-relevant electronic experience is connected to slower reading speeds when task competence is low.**

We expected a three-way interaction between situational competence and the two electronic reading experience measures to be a significant predictor of reading speed. Indeed, the interaction effect was significant:

```{r, warning='hide'}
speed_effectplot_electronicexperiencescomp <-
    interact_plot(Speed_RC_nested_selected3,
        pred = SCompetence.sc,
        modx = Eexp2DeviceRecFreq.sc,
        mod2 = Eexp1LongformEFreq.sc,
        data = reading_speed_measure_data,
        plot.points = FALSE,
        interval = TRUE,
        legend.main = "Electronic experience 2",
        mod2.labels = c("-1SD Electronic Experience 1", "Mean Electronic Experience 1", "+1SD Electronic Experience 1"),
        colors = c("orange", "darkred", "navy"),
        point.shape = TRUE
    ) +
    figure_theme_with_top_legend +
    labs(
        y = addline_format("Reading Speed as Proportion,of Baseline Speed"),
        x = "Situational competence score (centered and scaled)"
    )
```

The result indicates that when situational competence is low, a combination of both task-relevant electronic reading experience is associated with a baseline-level reading speed. When situational competence is high, on the other hand, this task-relevant electronic experience is associated with a higher than baseline reading speed. Therefore, task-relevant electronic experience may support participants engagement with the text when competence is low. This finding supports our hypotheses.

Whereas low task-relevant electronic experience (low score in both electronic measures) is connected to a similar patterns (when competence is high, speed tends to be higher than baseline, and when competence is low, speed tends to be baseline-level), a mismatch in electronic experience is associated with different trends. In particular, a low level of experience using task-relevant devices but a high level of experience in reading task-relevant text types electronically is associated with a higher than usual reading speed when competence is low, and a slow reading speed when competence is high. It is possible that participants without device-experience are not aware of device-relevant affordances or they may be more susceptible for shallowing effect than other participants.

#### Other results

In addition, reading speed was significantly predicted by contextual competence (CCompetence.sc).

**Contextual Competence**

```{r, warning='hide'}
speed_effectplot_contextualcompetence <- effect_plot(
    Speed_RC_nested_selected3,
    pred = "CCompetence.sc",
    data =  reading_speed_measure_data,
    plot.points = TRUE,
    point.size = 2,
    interval = TRUE,
    point.shape = TRUE
) +
    figure_theme_with_top_legend +
    labs(
        y = "Reading Speed as Proportion of Baseline Speed",
        x = addline_format("Contextual perceived competence, score (centered and scaled)")
    )
```

Contextual competence is positively linked to reading rate, indicating that a higher perceived reading ability is associated with the tendency to use speeds that are higher than baseline. In contrast, a lower reading ability is connected to baseline-level reading speed.

## Event Properties Model

The event properties model of linearity is used for explorative purposes, to study how speed varied during the study. As a result, the model specification is done differently from the reader characteristics model.

To explore meaningful random slope variables and interactions, we use data-driven selection. 

1. Additive intercepts-only model
2. Selection of random slopes with best-path algorithm
3. Backward selection if necessary
4. Interactive model structure with two-way interactions
5. Backward selection if necessary

1. We first specify an additive intercepts-only model with the following structure:

$Y_{i} = 
    \beta_{0} +
    # control variables
    WindowWidth +
    DUD +
    # predictors of interest
    Event~k-1~ +
    Event~k-2~ +
    ReadingSessionNumber +
    TimeInReadingSession +
    LocationInText +
    (1 | Story indicator / Participant indicator) +
    \varepsilon_{i}$ 

where
**$Y_{i}$** is the reading behaviour measure, in this case ReadingRate for reading speed (ReadingRate = speed/baseline speed).
**$\beta_{0}$** is the intercept
**WindowWidth** is a continuous measure of screen size, measured by window width in pixels (which is affected by device and has an effect on how much text is visible)
**DUD** is an acronym for 'DaysUntilDeadline' which tells us how much the participant has time left to read the short story. Days until deadline is used to control for variance in reading behaviour as a result of pressure to read the short story in time. For example, participants may read the text differently closer to the deadline compared to the beginning of the study.
**Event~k-1~** reflects the previous ReadingRate event. If the current event is k, then Event k-1 indicates reading rate at k-1
**Event~k-2~** reflects the ReadingRate event preceeding the previous. If the current event is k, then Event k-2 indicates reading rate at k-2
**ReadingSessionNumber** reflects the reading session number at event~k~ (outcome variable)
**TimeInReadingSession** indicates time passed since the beginning of the reading session at event~k~
**LocationInText** indicates location in text (in percentages) at event~k~
**(1 | Story indicator / Participant indicator)** indicates a nested random intercept of story and subject indicator. Each participant only read one short story during the study, and participant indicator is explicitly nested.
**$\varepsilon_{i}$** indicates the residual variance of $Y_{i}$

2. After specifying the additive intercepts-only model, we test inclusion of random slopes using the 'best-path' algorithm recommended by @barrRandomEffectsStructure2013a. With this method, we test inclusion of each predictor of interest as a random slope variable against the intercepts-only model. A liberal alpha-level of .20 is used. If multiple predictors contribute to the model with p < .2, we first accept the random slope with the lowest p-value. The testing is then resumed by comparing the inclusion of each of the remaining predictors as a random slope variable against the model with the previously accepted slope. This is continued until none of the predictors contribute to the model, and so all p > .2.

3. If the model does not converge or if it is singular after random slope selection, the model is simplified by backward stepwise selection. This is done by first removing random slopes from the model starting with the slope that accounts for the least variance. If the model remains nonconvergent or singular, fixed effects are removed one-by-one starting with the predictors that account for the least variance according to p-values. Significant fixed effects are not removed.

4-5. Once the additive model converges, we add two-way interactions in the model. Two-way interactions could be added between predictors measuring previous navigation events (Event~k-1~ and Event~k-2~) and between reading session number, time in reading session, and location in text. To avoid multicollinearity, interactions were not included between between previous navigation events and the other predictors in the model (e.g. Event~k-1~ was not allowed to interact with reading session number, time in reading session, or location in text). If the interactive model structure does not converge, it is simplified with backward stepwise selection.

This model selection is used to explore possible interactions that are meaningful to add without overfitting the model.

### Create missing predictor variables

```{r 'create-preceeding-event-variables'}
# order by User, reading session number and time since the beginning of a reading session
reading_speed_measure_data <-
    reading_speed_measure_data[
        with(
            reading_speed_measure_data,
            order(UserId, ReadingSessionNumber, FirstCumulativeRSTime)
        ),
    ]
# find previous events
reading_speed_measure_data$Observation_lag1 <- lag(reading_speed_measure_data$ReadingRate, 1)
reading_speed_measure_data$Observation_lag2 <- lag(reading_speed_measure_data$ReadingRate, 2)
#  create 'IsNewUser' test
reading_speed_measure_data$IsNewUser <- (reading_speed_measure_data$UserId != lag(reading_speed_measure_data$UserId, 1))
# confirm ordering
reading_speed_measure_data <-
    reading_speed_measure_data[
        with(
            reading_speed_measure_data,
            order(UserId, ReadingSessionNumber, FirstCumulativeRSTime)
        ),
    ]
# remove across participants comparisons
reading_speed_measure_data$Observation_lag1 <- ifelse(
    reading_speed_measure_data$IsNewUser, # current row is new user, cannot compare to previous
    NA,
    reading_speed_measure_data$Observation_lag1
)
reading_speed_measure_data$Observation_lag2 <- ifelse(
    lag(reading_speed_measure_data$IsNewUser, 1) |
    reading_speed_measure_data$IsNewUser, # current or previous row is new user, cannot compare to event k-2
    NA,
    reading_speed_measure_data$Observation_lag2
)
```

```{r 'create-location-in-%'}
reading_speed_measure_data$PercentageLocation <- (
    (reading_speed_measure_data$StartLocation
        / reading_speed_measure_data$CharacterLength)
)
```

### Visualise outcome variable and predictors

The reading_speed_measure_data has `r nrow(reading_speed_measure_data)` observations.

We create graphs to inspect speed of reading and its connection to other variables.
Graphs on the distribution of ReadingRate and connection to UserId, StoryId, DaysUntilDeadline, and WindowWidth were created before the reader characteristics model, and so they are not repeated here.

### Connection to previous event

We visualise connection to previous events to see if reading speed on the previous page, or on the page before the previous, is connected to reading speed on the current page-view.

Previous page-view:

```{r, include=FALSE}
ggplot(
    reading_speed_measure_data,
    aes(x = Observation_lag1, y = ReadingRate)
) +
    geom_point() +
    theme_classic()
```

Two pages before the current page-view:

```{r, include=FALSE}
ggplot(
    reading_speed_measure_data,
    aes(x = Observation_lag2, y = ReadingRate)
) +
    geom_point() +
    theme_classic()
```

### Reading session

Reading session number:

```{r, include=FALSE}
ggplot(
    reading_speed_measure_data,
    aes(x = ReadingSessionNumber, y = ReadingRate)
) +
    geom_jitter() +
    theme_classic()
```

Time in a reading session:

```{r, include=FALSE}
ggplot(
    reading_speed_measure_data,
    aes(x = FirstCumulativeRSTime, y = ReadingRate)
) +
    geom_point() +
    theme_classic() +
    labs(x = "Time in a reading session (min)")
```

### Location in text

```{r, include=FALSE}
ggplot(
    reading_speed_measure_data,
    aes(x = PercentageLocation * 100, y = ReadingRate)
) +
    geom_point() +
    theme_classic() +
    labs(x = "Location in text (%)")
```

Reading speed may increase towards the end of the text.

### Set contrasts to predictors

Predictors in the model are given contrasts. Continuous variables are scaled and centered, whereas categorical variables are given helmert contrasts. Helmert contrasts are used to control for uneven levels in categorical variables.

We scale and center continuous variables. These variables names are appended with ".cs" as a reminder that the variable is scaled and centered. Note that ReadingSessionNumber is treated as a continuous variable because we do not expect to see categorical differences between reading sessions, on the basis of the visualisations.

```{r 'scale-continuous-variables-2', echo=FALSE}
# Event k-1
reading_speed_measure_data$Observation_lag1.sc <-
    scale(reading_speed_measure_data$Observation_lag1,
        center = TRUE,
        scale = TRUE
    )
# Event k-2
reading_speed_measure_data$Observation_lag2.sc <-
    scale(reading_speed_measure_data$Observation_lag2,
        center = TRUE,
        scale = TRUE
    )
# Window width (control variable)
reading_speed_measure_data$WindowWidth.sc <-
    scale(reading_speed_measure_data$WindowWidth,
        center = TRUE,
        scale = TRUE
    )
# Days until reading deadline (control variable)
reading_speed_measure_data$DaysUntilDeadline.sc <-
    scale(reading_speed_measure_data$FirstTimeUntilDeadlineDays,
        center = TRUE,
        scale = TRUE
    )
# Reading session number
reading_speed_measure_data$ReadingSessionNumber.sc <-
    scale(reading_speed_measure_data$ReadingSessionNumber,
        center = TRUE,
        scale = TRUE
    )
# Time in a reading session
reading_speed_measure_data$TimeInReadingSession.sc <-
    scale(reading_speed_measure_data$FirstCumulativeRSTime,
        center = TRUE,
        scale = TRUE
    )
# Location in text
reading_speed_measure_data$PercentageLocation.sc <-
    scale(reading_speed_measure_data$PercentageLocation,
        center = TRUE,
        scale = TRUE
    )
```

### Modelling by Event Properties

#### Additive model

First, we build the additive intercepts-only model structure.

The model includes XX parameters before adding interactions, and `r nrow(reading_speed_measure_data)` observations. Previous research has suggested that each parameter in a model has at least 15 observations. Our sample exceeds this threshold considering that `r nrow(reading_speed_measure_data)`/10 = `r round(nrow(reading_speed_measure_data)/10, 2)`

```{r 'define-additive-model-structure'}
AdditiveStructure_EP_nested_interceptsonly <- (
    "ReadingRate ~ WindowWidth.sc + DaysUntilDeadline.sc + Observation_lag1.sc + Observation_lag2.sc + ReadingSessionNumber.sc + TimeInReadingSession.sc + PercentageLocation.sc + (1 | StoryId / UserId)"
)
```

Fit the additive, random-intercepts only model:

```{r 'fit-additive-model', warning='hide'}
Speed_EP_AdditiveModel_nested_interceptsonly <- lmer(
    AdditiveStructure_EP_nested_interceptsonly,
    data = reading_speed_measure_data,
    control = lmerControl(optimizer = "bobyqa")
)
```

We then add random slopes in the additive model by the 'best-path' algorithm described by @barrRandomEffectsStructure2013a.
With this method, we test addition of each fixed effect variable as a random slope using a liberal alpha-level (a = .20) against the intercepts-only model. If multiple variables contribute to the model with p < .20, we accept the variable with lowest p-value as slope, and resume testing by adding each fixed effect variable at a time as a random slope and compare to model with the previously accepted slope. This method allows us to explore meaningful random slopes with a data-driven approach.

```{r 'test-slopes1', eval=FALSE, echo=FALSE}
# slope test 1
    ## 1.1 WW
    ## 1.2 DUD
    ## 1.3 Event k-1
    ## 1.4 Event k-2
    ## 1.5 RSN
    ## 1.6 TRS
    ## 1.7 Loc
###################
# 1
AdditiveStructure_EP_nested_slope1_1 <- (
    "ReadingRate ~ WindowWidth.sc + DaysUntilDeadline.sc + Observation_lag1.sc + Observation_lag2.sc + ReadingSessionNumber.sc + TimeInReadingSession.sc + PercentageLocation.sc + (1 + WindowWidth.sc | StoryId / UserId)"
)
Speed_EP_AdditiveModel_nested1_1 <- lmer( # sing
    AdditiveStructure_EP_nested_slope1_1,
    data = reading_speed_measure_data,
    control = lmerControl(optimizer = "bobyqa"),
    REML = FALSE
)
anova(Speed_EP_AdditiveModel_nested_interceptsonly, Speed_EP_AdditiveModel_nested1_1) # WW does not contribute, p > .2
# 2
AdditiveStructure_EP_nested_slope1_2 <- (
    "ReadingRate ~ WindowWidth.sc + DaysUntilDeadline.sc + Observation_lag1.sc + Observation_lag2.sc + ReadingSessionNumber.sc + TimeInReadingSession.sc + PercentageLocation.sc + (1 + DaysUntilDeadline.sc | StoryId / UserId)"
)
Speed_EP_AdditiveModel_nested1_2 <- lmer(
    AdditiveStructure_EP_nested_slope1_2,
    data = reading_speed_measure_data,
    control = lmerControl(optimizer = "bobyqa"),
    REML = FALSE
)
anova(Speed_EP_AdditiveModel_nested1_2, Speed_EP_AdditiveModel_nested_interceptsonly) # DUD sig contributes, p = .0017
# 3
AdditiveStructure_EP_nested_slope1_3 <- (
    "ReadingRate ~ WindowWidth.sc + DaysUntilDeadline.sc + Observation_lag1.sc + Observation_lag2.sc + ReadingSessionNumber.sc + TimeInReadingSession.sc + PercentageLocation.sc + (1 + Observation_lag1.sc | StoryId / UserId)"
)
Speed_EP_AdditiveModel_nested1_3 <- lmer( # sing
    AdditiveStructure_EP_nested_slope1_3,
    data = reading_speed_measure_data,
    control = lmerControl(optimizer = "bobyqa"),
    REML = FALSE
)
anova(Speed_EP_AdditiveModel_nested1_3, Speed_EP_AdditiveModel_nested_interceptsonly) # sig contributes, p = .041
# 4
AdditiveStructure_EP_nested_slope1_4 <- (
    "ReadingRate ~ WindowWidth.sc + DaysUntilDeadline.sc + Observation_lag1.sc + Observation_lag2.sc + ReadingSessionNumber.sc + TimeInReadingSession.sc + PercentageLocation.sc + (1 + Observation_lag2.sc | StoryId / UserId)"
)
Speed_EP_AdditiveModel_nested1_4 <- lmer( # sing
    AdditiveStructure_EP_nested_slope1_4,
    data = reading_speed_measure_data,
    control = lmerControl(optimizer = "bobyqa"),
    REML = FALSE
)
anova(Speed_EP_AdditiveModel_nested1_4, Speed_EP_AdditiveModel_nested_interceptsonly) # contributes, p = .187
# 5
AdditiveStructure_EP_nested_slope1_5 <- (
    "ReadingRate ~ WindowWidth.sc + DaysUntilDeadline.sc + Observation_lag1.sc + Observation_lag2.sc + ReadingSessionNumber.sc + TimeInReadingSession.sc + PercentageLocation.sc + (1 + ReadingSessionNumber.sc | StoryId / UserId)"
)
Speed_EP_AdditiveModel_nested1_5 <- lmer(
    AdditiveStructure_EP_nested_slope1_5,
    data = reading_speed_measure_data,
    control = lmerControl(optimizer = "bobyqa"),
    REML = FALSE
)
anova(Speed_EP_AdditiveModel_nested1_5, Speed_EP_AdditiveModel_nested_interceptsonly) # sig contributes, p = .0032
# 6
AdditiveStructure_EP_nested_slope1_6 <- (
    "ReadingRate ~ WindowWidth.sc + DaysUntilDeadline.sc + Observation_lag1.sc + Observation_lag2.sc + ReadingSessionNumber.sc + TimeInReadingSession.sc + PercentageLocation.sc + (1 + TimeInReadingSession.sc | StoryId / UserId)"
)
Speed_EP_AdditiveModel_nested1_6 <- lmer(
    AdditiveStructure_EP_nested_slope1_6,
    data = reading_speed_measure_data,
    control = lmerControl(optimizer = "bobyqa"),
    REML = FALSE
)
anova(Speed_EP_AdditiveModel_nested1_6, Speed_EP_AdditiveModel_nested_interceptsonly) # does not contribute, p > .2
# 7
AdditiveStructure_EP_nested_slope1_7 <- (
    "ReadingRate ~ WindowWidth.sc + DaysUntilDeadline.sc + Observation_lag1.sc + Observation_lag2.sc + ReadingSessionNumber.sc + TimeInReadingSession.sc + PercentageLocation.sc + (1 + PercentageLocation.sc | StoryId / UserId)"
)
Speed_EP_AdditiveModel_nested1_7 <- lmer(
    AdditiveStructure_EP_nested_slope1_7,
    data = reading_speed_measure_data,
    control = lmerControl(optimizer = "bobyqa"),
    REML = FALSE
)
anova(Speed_EP_AdditiveModel_nested1_7, Speed_EP_AdditiveModel_nested_interceptsonly) # sig contributes, p = .0012
```

Location in text contributes the most to the model, and so it is added as the first random slope.

```{r 'test-slopes2', eval=FALSE, echo=FALSE}
# slope test 2
## Start adding all slopes again to the most sig slope: Loc
    ## 2.1: WW
    ## 2.2: DUD
    ## 2.3: Event k-1
    ## 2.4: Event k-2
    ## 2.5: RSN
    ## 2.6: TRS
###################
AdditiveStructure_EP_nested_slope2 <- (
    "ReadingRate ~ WindowWidth.sc + DaysUntilDeadline.sc + Observation_lag1.sc + Observation_lag2.sc + ReadingSessionNumber.sc + TimeInReadingSession.sc + PercentageLocation.sc + (1 + PercentageLocation.sc | StoryId / UserId)"
)
Speed_EP_AdditiveModel_nested2 <- lmer(
    AdditiveStructure_EP_nested_slope2,
    data = reading_speed_measure_data,
    control = lmerControl(optimizer = "bobyqa"),
    REML = FALSE
)
## 2_1
AdditiveStructure_EP_nested_slope2_1 <- (
    "ReadingRate ~ WindowWidth.sc + DaysUntilDeadline.sc + Observation_lag1.sc + Observation_lag2.sc + ReadingSessionNumber.sc + TimeInReadingSession.sc + PercentageLocation.sc + (1 + PercentageLocation.sc + WindowWidth.sc | StoryId / UserId)"
)
Speed_EP_AdditiveModel_nested2_1 <- lmer( # sing
    AdditiveStructure_EP_nested_slope2_1,
    data = reading_speed_measure_data,
    control = lmerControl(optimizer = "bobyqa"),
    REML = FALSE
)
anova(Speed_EP_AdditiveModel_nested2, Speed_EP_AdditiveModel_nested2_1) # does not contribute, p > .2
## 2_2
AdditiveStructure_EP_nested_slope2_2 <- (
    "ReadingRate ~ WindowWidth.sc + DaysUntilDeadline.sc + Observation_lag1.sc + Observation_lag2.sc + ReadingSessionNumber.sc + TimeInReadingSession.sc + PercentageLocation.sc + (1 + PercentageLocation.sc + DaysUntilDeadline.sc | StoryId / UserId)"
)
Speed_EP_AdditiveModel_nested2_2 <- lmer( # sing
    AdditiveStructure_EP_nested_slope2_2,
    data = reading_speed_measure_data,
    control = lmerControl(optimizer = "bobyqa"),
    REML = FALSE
)
anova(Speed_EP_AdditiveModel_nested2, Speed_EP_AdditiveModel_nested2_2) # sig contributes, p = .031
## 2_3
AdditiveStructure_EP_nested_slope2_3 <- (
    "ReadingRate ~ WindowWidth.sc + DaysUntilDeadline.sc + Observation_lag1.sc + Observation_lag2.sc + ReadingSessionNumber.sc + TimeInReadingSession.sc + PercentageLocation.sc + (1 + PercentageLocation.sc + Observation_lag1.sc | StoryId / UserId)"
)
Speed_EP_AdditiveModel_nested2_3 <- lmer( # sing
    AdditiveStructure_EP_nested_slope2_3,
    data = reading_speed_measure_data,
    control = lmerControl(optimizer = "bobyqa"),
    REML = FALSE
)
anova(Speed_EP_AdditiveModel_nested2, Speed_EP_AdditiveModel_nested2_3) # contributes, p = .064
## 2_4
AdditiveStructure_EP_nested_slope2_4 <- (
    "ReadingRate ~ WindowWidth.sc + DaysUntilDeadline.sc + Observation_lag1.sc + Observation_lag2.sc + ReadingSessionNumber.sc + TimeInReadingSession.sc + PercentageLocation.sc + (1 + PercentageLocation.sc + Observation_lag2.sc | StoryId / UserId)"
)
Speed_EP_AdditiveModel_nested2_4 <- lmer( # sing
    AdditiveStructure_EP_nested_slope2_4,
    data = reading_speed_measure_data,
    control = lmerControl(optimizer = "bobyqa"),
    REML = FALSE
)
anova(Speed_EP_AdditiveModel_nested2, Speed_EP_AdditiveModel_nested2_4) # does not contribute, p > .2
## 2_5
AdditiveStructure_EP_nested_slope2_5 <- (
    "ReadingRate ~ WindowWidth.sc + DaysUntilDeadline.sc + Observation_lag1.sc + Observation_lag2.sc + ReadingSessionNumber.sc + TimeInReadingSession.sc + PercentageLocation.sc + (1 + PercentageLocation.sc + ReadingSessionNumber.sc | StoryId / UserId)"
)
Speed_EP_AdditiveModel_nested2_5 <- lmer( # sing
    AdditiveStructure_EP_nested_slope2_5,
    data = reading_speed_measure_data,
    control = lmerControl(optimizer = "bobyqa"),
    REML = FALSE
)
anova(Speed_EP_AdditiveModel_nested2, Speed_EP_AdditiveModel_nested2_5) # does not contribute, p > .2
## 2_6
AdditiveStructure_EP_nested_slope2_6 <- (
    "ReadingRate ~ WindowWidth.sc + DaysUntilDeadline.sc + Observation_lag1.sc + Observation_lag2.sc + ReadingSessionNumber.sc + TimeInReadingSession.sc + PercentageLocation.sc + (1 + PercentageLocation.sc + TimeInReadingSession.sc | StoryId / UserId)"
)
Speed_EP_AdditiveModel_nested2_6 <- lmer( # sing
    AdditiveStructure_EP_nested_slope2_6,
    data = reading_speed_measure_data,
    control = lmerControl(optimizer = "bobyqa"),
    REML = FALSE
)
anova(Speed_EP_AdditiveModel_nested2, Speed_EP_AdditiveModel_nested2_6) # contributes, p = .125
```

Days until deadline contributes the most to the model in slope test round 2. It is added in the model in addition to location in text.

```{r 'test-slopes3', eval=FALSE, echo=FALSE}
# slope test 3
## Start adding all slopes again to the most sig slopes: LOC + DUD
    ## 3_1: WW
    ## 3_2: Event k-1
    ## 3_3: Event k-2
    ## 3_4: RSN
    ## 3_5: TRS
###################
AdditiveStructure_EP_nested_slope3 <- (
    "ReadingRate ~ WindowWidth.sc + DaysUntilDeadline.sc + Observation_lag1.sc + Observation_lag2.sc + ReadingSessionNumber.sc + TimeInReadingSession.sc + PercentageLocation.sc + (1 + PercentageLocation.sc + DaysUntilDeadline.sc | StoryId / UserId)"
)
Speed_EP_AdditiveModel_nested3 <- lmer( # sing
    AdditiveStructure_EP_nested_slope3,
    data = reading_speed_measure_data,
    control = lmerControl(optimizer = "bobyqa"),
    REML = FALSE
)
## 3_1
AdditiveStructure_EP_nested_slope3_1 <- (
    "ReadingRate ~ WindowWidth.sc + DaysUntilDeadline.sc + Observation_lag1.sc + Observation_lag2.sc + ReadingSessionNumber.sc + TimeInReadingSession.sc + PercentageLocation.sc + (1 + PercentageLocation.sc + DaysUntilDeadline.sc + WindowWidth.sc | StoryId / UserId)"
)
Speed_EP_AdditiveModel_nested3_1 <- lmer( # sing, nc
    AdditiveStructure_EP_nested_slope3_1,
    data = reading_speed_measure_data,
    control = lmerControl(optimizer = "bobyqa"),
    REML = FALSE
)
anova(Speed_EP_AdditiveModel_nested3, Speed_EP_AdditiveModel_nested3_1) # does not contribute, p > .2
## 3_2
AdditiveStructure_EP_nested_slope3_2 <- (
    "ReadingRate ~ WindowWidth.sc + DaysUntilDeadline.sc + Observation_lag1.sc + Observation_lag2.sc + ReadingSessionNumber.sc + TimeInReadingSession.sc + PercentageLocation.sc + (1 + PercentageLocation.sc + DaysUntilDeadline.sc + Observation_lag1.sc | StoryId / UserId)"
)
Speed_EP_AdditiveModel_nested3_2 <- lmer( # sing, nc
    AdditiveStructure_EP_nested_slope3_2,
    data = reading_speed_measure_data,
    control = lmerControl(optimizer = "bobyqa"),
    REML = FALSE
)
anova(Speed_EP_AdditiveModel_nested3, Speed_EP_AdditiveModel_nested3_2) # does not contribute, p > .2
## 3_3
AdditiveStructure_EP_nested_slope3_3 <- (
    "ReadingRate ~ WindowWidth.sc + DaysUntilDeadline.sc + Observation_lag1.sc + Observation_lag2.sc + ReadingSessionNumber.sc + TimeInReadingSession.sc + PercentageLocation.sc + (1 + PercentageLocation.sc + DaysUntilDeadline.sc + Observation_lag2.sc | StoryId / UserId)"
)
Speed_EP_AdditiveModel_nested3_3 <- lmer( # sing, nc
    AdditiveStructure_EP_nested_slope3_3,
    data = reading_speed_measure_data,
    control = lmerControl(optimizer = "bobyqa"),
    REML = FALSE
)
anova(Speed_EP_AdditiveModel_nested3, Speed_EP_AdditiveModel_nested3_3) # does not contribute, p > .2
## 3_4
AdditiveStructure_EP_nested_slope3_4 <- (
    "ReadingRate ~ WindowWidth.sc + DaysUntilDeadline.sc + Observation_lag1.sc + Observation_lag2.sc + ReadingSessionNumber.sc + TimeInReadingSession.sc + PercentageLocation.sc + (1 + PercentageLocation.sc + DaysUntilDeadline.sc + ReadingSessionNumber.sc | StoryId / UserId)"
)
Speed_EP_AdditiveModel_nested3_4 <- lmer( # sing
    AdditiveStructure_EP_nested_slope3_4,
    data = reading_speed_measure_data,
    control = lmerControl(optimizer = "bobyqa"),
    REML = FALSE
)
anova(Speed_EP_AdditiveModel_nested3, Speed_EP_AdditiveModel_nested3_4) # does not contribute, p > .2
## 3_5
AdditiveStructure_EP_nested_slope3_5 <- (
    "ReadingRate ~ WindowWidth.sc + DaysUntilDeadline.sc + Observation_lag1.sc + Observation_lag2.sc + ReadingSessionNumber.sc + TimeInReadingSession.sc + PercentageLocation.sc + (1 + PercentageLocation.sc + DaysUntilDeadline.sc + TimeInReadingSession.sc | StoryId / UserId)"
)
Speed_EP_AdditiveModel_nested3_5 <- lmer( # sing
    AdditiveStructure_EP_nested_slope3_5,
    data = reading_speed_measure_data,
    control = lmerControl(optimizer = "bobyqa"),
    REML = FALSE
)
anova(Speed_EP_AdditiveModel_nested3, Speed_EP_AdditiveModel_nested3_5) # does not contribute, p > .2
```

None of the remaining slopes significantly add to the model, and so our final additive model includes random slopes for location in text, and days until reading deadline.
Refit the additive model with REML:

```{r 'refit-additive-model-with-REML', warning='hide'}
AdditiveStructure_EP_nested_slope3 <- (
    "ReadingRate ~ WindowWidth.sc + DaysUntilDeadline.sc + Observation_lag1.sc + Observation_lag2.sc + ReadingSessionNumber.sc + TimeInReadingSession.sc + PercentageLocation.sc + (1 + PercentageLocation.sc + DaysUntilDeadline.sc | StoryId / UserId)"
)
Speed_EP_AdditiveModel_nested_slopes <- lmer(
    AdditiveStructure_EP_nested_slope3,
    data = reading_speed_measure_data,
    control = lmerControl(optimizer = "bobyqa"),
    REML = TRUE
)
```

The additive model with random slopes is singular. To address this, we simplify the model backward stepwise.
Selection is done according to the following priority:

    1. Remove slopes that account for the lowest amount of variance
    2. Remove fixed effects that contribute the least to the model, according to p-values

Selection is done manually, removing a single variable at a time. Selection is only done until the additive model converges and is no longer singular.

```{r 'ep-backward-stepwise-selection-slopes', eval=FALSE, echo=FALSE}
# backward-selection of slopes
## 1: remove the slope that accounts for the least variance, until convergence
##########
# see which slope accounts for the lowest amount of variance
summary(Speed_EP_AdditiveModel_nested_slopes) # Location accounts for the least variance
# Remove Location slope
AdditiveStructure_EP_nested_slope5_1 <- (
    "ReadingRate ~ WindowWidth.sc + DaysUntilDeadline.sc + Observation_lag1.sc + Observation_lag2.sc + ReadingSessionNumber.sc + TimeInReadingSession.sc + PercentageLocation.sc + (1 + DaysUntilDeadline.sc | StoryId / UserId)"
)
AdditiveStructure_EP_nested_slope5_1 <- lmer(
    AdditiveStructure_EP_nested_slope5_1,
    data = reading_speed_measure_data,
    control = lmerControl(optimizer = "bobyqa")
)
```

The additive model converges after removal of the random slope of location in text. The final additive model includes a random slope of days until reading deadline only.
Inspect model values:

```{r, warning='hide'}
AdditiveStructure_EP_nested_slope5_1 <- (
    "ReadingRate ~ WindowWidth.sc + DaysUntilDeadline.sc + Observation_lag1.sc + Observation_lag2.sc + ReadingSessionNumber.sc + TimeInReadingSession.sc + PercentageLocation.sc + (1 + DaysUntilDeadline.sc | StoryId / UserId)"
)
AdditiveStructure_EP_nested_slope5_1 <- lmer(
    AdditiveStructure_EP_nested_slope5_1,
    data = reading_speed_measure_data,
    control = lmerControl(optimizer = "bobyqa")
)
summary(AdditiveStructure_EP_nested_slope5_1)
plot(AdditiveStructure_EP_nested_slope5_1)
fixef(AdditiveStructure_EP_nested_slope5_1)
```

We then add interactions to the additive model.

#### Interactive model

We create a new model structure with interactions between predictors of interest (all main effects apart from DaysUntilDeadline and WindowWidth which are used as control variables only).
Only two-way interactions are included to avoid overfitting the model. No interactions are included between previous events (Observation_lag1 and Observation_lag2) and other predictors in the model (e.g. ReadingSessionNumber) to avoid multicollinearity.

To start, the interactive model includes XX parameters (including the intercept, random effects, main effects, interactions). Previous research has suggested that each parameter in a model has at least 15 observations. Our sample exceeds this threshold considering that `r nrow(reading_speed_measure_data)`/14 = `r round(nrow(reading_speed_measure_data)/14, 2)`.

```{r 'define-interactive-structure'}
InteractiveStructure_EP_nested_slopes <- (
    "ReadingRate ~ WindowWidth.sc + DaysUntilDeadline.sc + Observation_lag1.sc + Observation_lag2.sc + ReadingSessionNumber.sc + TimeInReadingSession.sc + PercentageLocation.sc + Observation_lag1.sc : Observation_lag2.sc + ReadingSessionNumber.sc : TimeInReadingSession.sc + ReadingSessionNumber.sc : PercentageLocation.sc + TimeInReadingSession.sc : PercentageLocation.sc + (1 + DaysUntilDeadline.sc | StoryId / UserId)"
)
```

```{r 'fit-interactive-model', warning='hide'}
Speed_EP_InteractiveModel_nested_slopes <- lmer(
    InteractiveStructure_EP_nested_slopes,
    data = reading_speed_measure_data,
    control = lmerControl(optimizer = "bobyqa"),
    REML = TRUE
)
```

The full interactive model structure converges.
Inspect model values:

```{r, include=FALSE}
summary(Speed_EP_InteractiveModel_nested_slopes)
plot(Speed_EP_InteractiveModel_nested_slopes)
fixef(Speed_EP_InteractiveModel_nested_slopes)
```

### Model Assumptions

All linear mixed models were tested for (1) multicollinearity, (2) influential observations, (3) heteroscedasticity, (4) normality of random effects, and (5) normality of residuals.

#### 1. Multicollinearity

We check for multicollinearity first with a correlation matrix:

```{r, eval=FALSE, include=FALSE}
corrplot(cor(remove_missing(reading_speed_measure_data[, c(
    "Observation_lag1.sc",
    "Observation_lag2.sc",
    "WindowWidth.sc",
    "DaysUntilDeadline.sc",
    "ReadingSessionNumber.sc",
    "TimeInReadingSession.sc",
    "PercentageLocation.sc"
    )])), method = "number")
```

None of the predictors show high correlations.

We then calculate Variance Inflation Factors (VIF):

```{r, eval=FALSE, include=FALSE}
check_collinearity(Speed_EP_InteractiveModel_nested_slopes)
plot(check_collinearity(Speed_EP_InteractiveModel_nested_slopes))
```

The model predictors do not seem to be multicollinear. All VIF < 2, and usually VIF > 5 is used as an indicator of potential multicollinearity.

#### 2. Influential Observations

We test influential observations with Cook's Distance:

```{r}
cooksd <-
     cooks.distance(Speed_EP_InteractiveModel_nested_slopes)
```

```{r, eval=FALSE, include=FALSE}
plot(cooksd,
     pch = "*",
     cex = 2,
     main = "Influential Obs by Cooks Distance"
)
abline(h = 4 * mean(cooksd, na.rm = TRUE), col = "red")
text(
     x = 1:length(cooksd) + 1,
    y = cooksd,
    labels = ifelse(cooksd > 4 * mean(cooksd, na.rm = TRUE), names(cooksd), ""),
    col = "red"
)
```

The plot indicates that the dataset may include some influential observations. However, the cook's distances are very conservative as the threshold is set at `r 4 * mean(cooksd, na.rm = TRUE)`. Therefore, it is unlikely that these observations influence the model.

To further test influential observations we use performance::check_outliers:

```{r, eval=FALSE, include=FALSE}
check_outliers(Speed_EP_InteractiveModel_nested_slopes)
plot(check_outliers(Speed_EP_InteractiveModel_nested_slopes))
```

Although Cook's Distance indicates that the model has influential observations, the outlier test does not produce the same results. Considering the conservative Cook's Distance limit, we assume that the model does not have influential outliers.

#### 3. Heteroscedasticity

We use the Breusch-Pagan test to check whether the variances of residuals in the model vary systematically:

```{r, eval=FALSE, include=FALSE}
check_heteroscedasticity(Speed_EP_InteractiveModel_nested_slopes)
plot(check_heteroscedasticity(Speed_EP_InteractiveModel_nested_slopes))
```

The test is not significant, indicating that the variances are homoscedastic in the model.
The model aligns with the assumption of homoscedasticity.

#### 4. Normality of Random Effects

Random effects should be normally distributed in multilevel models. We test this assumption by inspecting first the normality of 'UserId' and then 'StoryId' random intercepts.

```{r, eval=FALSE, include=FALSE}
random_intercept_UserId <- ranef(Speed_EP_InteractiveModel_nested_slopes)$UserId$`(Intercept)`
qqnorm(random_intercept_UserId)
qqline(random_intercept_UserId)
shapiro.test(random_intercept_UserId)
```

The qqplot varies slightly from the reference line, however, the Shapiro Test is not significant, and so we assume normality of UserId.

```{r, eval=FALSE, include=FALSE}
random_intercept_StoryId <- ranef(Speed_EP_InteractiveModel_nested_slopes)$StoryId$`(Intercept)`
qqnorm(random_intercept_StoryId)
qqline(random_intercept_StoryId)
shapiro.test(random_intercept_StoryId)
```

StoryId aligns much worse with the reference line, however, this is expected considering that StoryId only includes 9 different story groups. With the limited amount of information, achieving a visually normally distributed result is unlikely. Considering that the Shapiro Test is not significant, we can assume that StoryId random intercept is normally distributed.

#### 5. Normality of residuals

We first check normality of residuals by plotting model residuals and fitted values

```{r, eval=FALSE, include=FALSE}
plot(resid(Speed_EP_InteractiveModel_nested_slopes), fitted(Speed_EP_InteractiveModel_nested_slopes))
```

The model residuals are not symmetrically scattered in the plot, as the model observations seem to cluster around specific values.

To further check non-normality, we use a qqplot:

```{r, eval=FALSE, include=FALSE}
qqnorm(residuals(Speed_EP_InteractiveModel_nested_slopes))
```

The qqplot shows slight variation from normality. However, the variation is not very extensive. Assess normality with a histogram of residuals:

```{r, eval=FALSE, include=FALSE}
hist(resid(Speed_EP_InteractiveModel_nested_slopes), breaks = 100)
```

The histogram shows a roughly normal distribution. We then inspect skewness and kurtosis in residuals:

```{r, eval=FALSE, include=FALSE}
# 0 - normal, neg - left skew, pos - right skew
skewness(resid(Speed_EP_InteractiveModel_nested_slopes))
# 3 - normal, <3 playkurtic, >3 leptokurtic
kurtosis(resid(Speed_EP_InteractiveModel_nested_slopes))
```

The residuals are slightly skewed to the right, and the distribution is leptokurtic.
Finally, we test normality with a Shapiro Wilkins test:

```{r, eval=FALSE, include=FALSE}
# Shapiro Wilk Test
check_normality(Speed_EP_InteractiveModel_nested_slopes)
```

Shapiro Wilk test is significant, indicating of variance from the normal distribution.

However, the visualisations do not raise any significant concerns with normality. Shapiro Wilk test is affected by large sample sizes, and thus the resulting significant p-value may be an indication of a statistically but not practically significant variation from normality due to the large n (*n* = `r nrow(reading_speed_measure_data)`).Furthermore, consultation of resources on mixed modelling indicated that violating the normality of residuals assumption in this case may not be undermine the model quality. For example, @gelman_data_2007 mention that "the assumption of normality is barely important at all. Thus, [..] we do *not* recommed diagnostics of the normality of regression residuals".

As a result, we assume that the residuals are distributed normally enough for our purposes. 

**Assumptions conclusion**

The model aligns with all assumptions.

### Interpret model

We then inspect model effects to interpret the results.

```{r, include=FALSE}
summary(Speed_EP_InteractiveModel_nested_slopes)
```

In the event properties model, the following variables are significant predictors of reading rate:
(1) Main effect of Observation_lag1 (Event~k-1~)
(2) Main effect of Observation_lag2 (Event~k-2~)
(3) Main effect of PercentageLocation

We first inspect the previous events (1-2), and then the remaining main effect (3).

#### Inspect impact of previous event

Observation_lag1 was a significant predictor of reading rate.

```{r, warning='hide'}
speed_ep_previouslag1 <- effect_plot(
    Speed_EP_InteractiveModel_nested_slopes,
    pred = Observation_lag1.sc,
    plot.points = TRUE,
    point.alpha = .2,
    interval = TRUE
) +
    figure_theme_without_legend +
    labs(
        y = "Reading Speed as Proportion of Baseline Speed",
        x = addline_format("Event~k-1~:,Reading speed on previous page,(centered and scaled)")
    )
(summary(Speed_EP_InteractiveModel_nested_slopes)$varcor[1])
```

There is a slight positive trend which indicates that a high reading speed on previous page-view (event k-1) predicts a high reading speed on the following page (event k).

Similarly, reading speed on the page before the previous (event k-2) was positively connected to reading speed (event k).

```{r, warning='hide'}
speed_ep_previouslag2 <- effect_plot(
    Speed_EP_InteractiveModel_nested_slopes,
    pred = Observation_lag2.sc,
    plot.points = TRUE,
    point.alpha = .2,
    interval = TRUE
) +
    figure_theme_without_legend +
    labs(
        y = "Reading Speed as Proportion of Baseline Speed",
        x = addline_format("Event~k-2~:,Reading speed on the page before previous page,(centered and scaled)")
    )
```

This indicates that consecutive pages were often navigated at the same speed.

#### Impact of location in text

In addition to Observation_lag1 and Observation_lag2, reading speed was significantly predicted by PercentageLocation.

```{r, warning='hide'}
speed_ep_location <- effect_plot(
    Speed_EP_InteractiveModel_nested_slopes,
    pred = PercentageLocation.sc,
    plot.points = TRUE,
    point.alpha = .2,
    interval = TRUE
) +
    figure_theme_without_legend +
    labs(
        y = "Reading Speed as Proportion of Baseline Speed",
        x = "Location in Text (%, centered and scaled)"
    )
```

Location and reading speed were positively correlated, indicating that participants had a tendency to increase their reading speed towards the end of the document.